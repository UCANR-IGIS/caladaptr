[{"path":"https://ucanr-igis.github.io/caladaptr/articles/api-requests.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"API Requests","text":"can fetch data kind Cal-Adapt, construct API request object. Creating API request object like filling order form. completed, feed API request function actually retrieves data (either tabular raster). API request object contains information needed fetch data, including location(s) interest, dataset(s), time period. practice, construct API request object stringing together series functions specify different pieces request. Examples:","code":"library(caladaptr)  ## Request modeled climate data (from Scripps) sac_minmaxtemp_cap <- ca_loc_pt(coords = c(-121.4687, 38.5938)) %>%    ## pointlocation(s)   ca_gcm(c(\"HadGEM2-ES\", \"CNRM-CM5\", \"CanESM2\",\"MIROC5\")) %>%          ## GCM(s)   ca_scenario(c(\"rcp45\",\"rcp85\")) %>%                                  ## emission scenarios(s)   ca_cvar(c(\"tasmin\", \"tasmax\")) %>%                                   ## climate variables   ca_period(\"year\") %>%                                                ## temporal aggregation period   ca_years(start = 1971, end = 2070)                                   ## start and end dates  ## Specify Livneh data (observed historical) for a HUC10 watershed huc_pr_cap <- ca_loc_aoipreset(type = \"hydrounits\",                    ## Preset AOI                                idfld = \"huc10\",                                idval = \"1809020409\") %>%   ca_livneh(TRUE) %>%                                                  ## Livneh data   ca_cvar(\"pr\") %>%                                                    ## precipitation   ca_period(\"day\") %>%                                                 ## daily   ca_dates(start = \"1960-10-01\", end = \"2010-09-30\") %>%               ## start and end dates   ca_options(spatial_ag = \"mean\")                                      ## spatially aggregate w/ mean  ## Specify desired data by slug for irrigated water management districts irwm_ht_cap <- ca_loc_aoipreset(type = \"irwm\", idfld = \"name\") %>%     ## Preset AOI   ca_slug(c(\"exheat_year_ens32avg_historical\",                         ## slug(s)             \"exheat_year_ens32avg_rcp45\",             \"exheat_year_ens32avg_rcp85\")) %>%   ca_options(spatial_ag = \"max\")                                       ## spatially aggregate w/ max"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/api-requests.html","id":"specifying-location","dir":"Articles","previous_headings":"","what":"Specifying Location","title":"API Requests","text":"API requests must specify location(s) interest. Locations can specified points, preset areas--interest, user-provided geoms. options allow specify primary key field included results results can joined input features.  1) Points Point locations can included using ca_loc_pt() points saved vector, matrix data frame, ca_loc_sf() points simple feature data frame. points passed matrix, vector data frame, first column longitude (x), second column latitude (y). Geographic coordinates required points sf data frame (good idea). Example:  2) Preset areas--interest Cal-Adapt API integrated number preset polygon areas--interest, also referred boundary layers. things like county boundaries, census tracts, watersheds, etc. study area(s) coincide one layers, can specify name using ca_loc_aoipreset(). see list available preset layers, run: use preset AOI layer API request, can specify feature(s) ’re interested (don’t want ). example want data summarized county, can specify 50 counties California ’re interested . Two arguments must passed specify features interest: ) idfld (field attribute table unique values), ii) idval (id numbers values features). Example: figure fields available specify locations given preset layer, can use built-constant aoipreset_idflds. example ’re interested counties, can use following fields: see valid values specify features, use built-constant aoipreset_idval. example, ‘Counties’ preset layer column named ‘fips’ can use specify county(s) ’re interested . values look like:  preset areas interest can imported sf objects using ca_aoipreset_geom(). example climate regions 5th climate change assessment look like:   3) User-provided sf features Cal-Adapt’s preset areas--interest don’t align study area(s), can provide locations simple feature data frame. sf object column unique values (like OBJECTID) join input features Cal-Adapt data. Add locations sf object API request ca_loc_sf(). POINT, POLYGON, MULTIPOLYGON geometries supported. Lines supported, multipoint features must converted simple point features (see st_cast). idfld argument specifies column sf object contains unique values. sf object lacks column unique values, can add one using mutate(), provide vector unique id values idval. Cal-Adapt API limits large spatial area can queried. area--interest larger county, consider blocking area ca_biggeom_blocks(). locations include multiple points per 6km LOCA grid cell (Cal-Adapt’s smallest spatial unit), can group just make one call per grid cell (see Large Queries vignette sample code). next example, get sf data frame Congressional Districts, use start API request object.","code":"(ca_loc_pt(coords = c(-122.1, 38.1))) #> Cal-Adapt API Request #> Location(s):  #>   x: -122.1 #>   y: 38.1 #> aoipreset_types #>  [1] \"censustracts\"      \"counties\"          \"cdistricts\"        \"ccc4aregions\"      \"climregions\"       \"hydrounits\"        \"irwm\"              #>  [8] \"electricutilities\" \"wecc-load-area\"    \"evtlocations\"      \"place\" (ca_loc_aoipreset(type = \"counties\", idfld = \"fips\", idval = \"06013\")) #> Cal-Adapt API Request #> Location(s):  #>   AOI Preset: counties #>   fips(s): 06013 #> aoipreset_idflds$counties #> [1] \"fips\" \"id\" aoipreset_idval$counties$fips %>% head() #> [1] \"06001\" \"06003\" \"06005\" \"06007\" \"06009\" \"32510\" ca_climregions_sf <- ca_aoipreset_geom(\"climregions\") #> Reading layer `climregions' from data source `C:\\Users\\Andy\\AppData\\Local\\R\\cache\\R\\caladaptr\\climregions.gpkg' using driver `GPKG' #> Simple feature collection with 11 features and 2 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: -13848750 ymin: 3833695 xmax: -12705800 ymax: 5163721 #> Projected CRS: WGS 84 / Pseudo-Mercator  library(ggplot2) ggplot(ca_climregions_sf) + geom_sf(aes(fill = name)) ## Get Congressional Districts as a sf object (cdistricts_sf <- ca_aoipreset_geom(\"cdistricts\", quiet = TRUE)) #> Simple feature collection with 66 features and 9 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: -13866650 ymin: 3675964 xmax: -12138860 ymax: 6275056 #> Projected CRS: WGS 84 / Pseudo-Mercator #> First 10 features: #>    statefp cd114fp      affgeoid geoid lsad cdsessn        aland     awater id                           geom #> 1       06      11 5001400US0611  0611   C2     114   1278249894   92424585  1 MULTIPOLYGON (((-13628819 4... #> 2       06      41 5001400US0641  0641   C2     114    819873792    4240410  2 MULTIPOLYGON (((-13086531 4... #> 3       16      02 5001400US1602  1602   C2     114 111948989280 1081502469  3 MULTIPOLYGON (((-12950296 5... #> 4       06      50 5001400US0650  0650   C2     114   7219205047   43666727  4 MULTIPOLYGON (((-13053482 3... #> 5       06      16 5001400US0616  0616   C2     114   7354278768  118616551  5 MULTIPOLYGON (((-13497338 4... #> 6       49      02 5001400US4902  4902   C2     114 103638076153 2945583941  6 MULTIPOLYGON (((-12696318 4... #> 7       06      49 5001400US0649  0649   C2     114   1432623041  512378639  7 MULTIPOLYGON (((-13105979 3... #> 8       06      08 5001400US0608  0608   C2     114  85126210480  450307265  8 MULTIPOLYGON (((-13319259 4... #> 9       06      20 5001400US0620  0620   C2     114  12624185548 1574913163  9 MULTIPOLYGON (((-13589114 4... #> 10      06      32 5001400US0632  0632   C2     114    321774529    5320498 10 MULTIPOLYGON (((-13143818 4...  ## Start an API request object (ca_loc_sf(loc = cdistricts_sf, idfld = \"geoid\")) #> Cal-Adapt API Request #> Location(s):  #>   Simple Feature MULTIPOLYGON (66 feature(s)) #>   ID field: geoid #>"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/api-requests.html","id":"datasets","dir":"Articles","previous_headings":"","what":"Datasets","title":"API Requests","text":"Cal-Adapt API request must also specify data layers(s) retrieve. description datasets Cal-Adapt beyond scope vignette, general guidelines include: Review data documentation Cal-Adapt, including Introduction Climate Data webinar. local copy Cal-Adapt data catalog can retrieved ca_catalog_rs(), returns tibble. One way find dataset project view catalog RStudio viewer pane use filter tool find specific datasets. search data layers view properties, can use ca_catalog_search(), passing keywords slug. Partial matches returned well.","code":"View(ca_catalog_rs()) ca_catalog_search(\"pr_day_gridmet\") #>  #> pr_day_gridmet #>   name: gridMET daily precipitation historical #>   url: https://api.cal-adapt.org/api/series/pr_day_gridmet/ #>   tres: daily #>   begin: 1979-01-01T00:00:00Z #>   end: 2020-12-31T00:00:00Z #>   units: mm #>   num_rast: 1 #>   id: 338 #>   xmin: -124.579167 #>   xmax: -113.370833 #>   ymin: 31.545833 #>   ymax: 43.754167"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/api-requests.html","id":"specifying-datasets","dir":"Articles","previous_headings":"Datasets","what":"Specifying Datasets","title":"API Requests","text":"’ve identified dataset need, add functions Cal-Adapt API request. groups functions use specify datasets fall three categories: 1) one main climate models, 2) observed climate data, 3) slugs.  Modeled Climate Data Many Cal-Adapt’s datasets based direct output global climate models (e.g., temperature, precipitation) derivatives (e.g., snow water equivalent, evaoptranspiration). models used predict future historic conditions based specific emissions scenarios. API requests modeled climate data include: climate variable(s) - e.g., tasmin, tasmax, pr, et, etc. GCM(s) emissions scenario(s) temporal period - e.g., year, day, month help construct API request modeled climate data, following built-constants provide valid values. Note combinations existing dataset. Example:  Observed Data Livneh data based historic records spatially interpolated. specify Livneh dataset, include ca_livneh() request omit GCMs emission scenarios:  Slugs nearly 950 raster series available Cal-Adapt API unique slug, short name. can look slugs Cal-Adapt catalog (ca_catalog_rs()). dataset ’re interested can’t specified using functions , can use ca_slug() specify slug. ca_slug(), don’t include climate variable, period, GCM, scenario - implied slug. ’ll still need specify location optionally dates API request complete.","code":"cvars #>  [1] \"tasmax\"     \"tasmin\"     \"pr\"         \"swe\"        \"baseflow\"   \"et\"         \"rainfall\"   \"runoff\"     \"snowfall\"   \"soilMoist1\" #> [11] \"Tair\"  gcms #>  [1] \"HadGEM2-ES\" \"CNRM-CM5\"   \"CanESM2\"    \"MIROC5\"     \"ACCESS1-0\"  \"CCSM4\"      \"CESM1-BGC\"  \"CMCC-CMS\"   \"GFDL-CM3\"   \"HadGEM2-CC\" #> [11] \"ens32avg\"   \"ens32max\"   \"ens32min\"  scenarios #> [1] \"rcp45\"      \"rcp85\"      \"historical\"  periods #> [1] \"day\"    \"month\"  \"year\"   \"30yavg\" (ca_cvar(cvar = \"tasmin\") %>%   ca_gcm(gcm = gcms[1:4]) %>%   ca_scenario(\"rcp85\") %>%   ca_period(\"year\")) #> Cal-Adapt API Request #> Location(s): NA #> Variable(s): tasmin #> Temporal aggregration period(s): year #> GCM(s): HadGEM2-ES, CNRM-CM5, CanESM2, MIROC5 #> Scenario(s): rcp85 #> (ex2_cap <- ca_cvar(cvar = \"pr\") %>%   ca_livneh(TRUE) %>%   ca_period(\"year\")) #> Cal-Adapt API Request #> Location(s): NA #> Variable(s): pr #> Temporal aggregration period(s): year #> Livneh data: TRUE #> (ca_slug(slug = \"exheat_year_ens32avg_historical\")) #> Cal-Adapt API Request #> Location(s): NA #> Slug(s): exheat_year_ens32avg_historical #>"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/api-requests.html","id":"dates","dir":"Articles","previous_headings":"","what":"Dates","title":"API Requests","text":"Date ranges optional API requests. date range provided, data entire time range dataset returned. can include date range ca_dates() ca_years(). Enter years integers, dates character values \"yyyy-mm-dd\". Examples:","code":"(ca_years(start = 2035, end = 2065)) #> Cal-Adapt API Request #> Location(s): NA #> Dates: 2035-01-01 to 2065-12-31 #>  (ca_dates(start = \"2050-03-15\", end = \"2070-10-31\")) #> Cal-Adapt API Request #> Location(s): NA #> Dates: 2050-03-15 to 2070-10-31 #>"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/api-requests.html","id":"options","dir":"Articles","previous_headings":"","what":"Options","title":"API Requests","text":"ca_options() specify options request. Currently option use spatial_ag. spatial_ag spatial aggregation function used querying polygon areas. feature intersects one LOCA grid cell, function used collapse grid cells one value.","code":"(ca_options(spatial_ag = \"mean\")) #> Cal-Adapt API Request #> Location(s): NA #> Options: #>   spatial ag: mean #>"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/api-requests.html","id":"checking-the-integrity-of-an-api-request","dir":"Articles","previous_headings":"","what":"Checking the integrity of an API request","title":"API Requests","text":"use API request fetch data, couple things can check validity. verify API request covers correct location, can plot . plot sample API request returned ca_example_apireq(). Adding locagrid = TRUE overlay actual LOCA grid cells.   ca_preflight() complete check API request, double-checking refers existing dataset, data available requested date range, request doesn’t conflicting elements, isn’t big, etc. warnings specific fetching values vs fetching rasters, reported accordingly:","code":"(samp_cap <- ca_example_apireq(3)) #> Cal-Adapt API Request #> Location(s):  #>   Simple Feature POLYGON (1 feature(s)) #>   ID field: id #> Variable(s): pr #> Temporal aggregration period(s): day #> GCM(s): CCSM4 #> Scenario(s): rcp85 #> Dates: 2010-01-01 to 2012-12-31 #> Options: #>   spatial ag: mean #>   # Omit `static = TRUE` to get an interactive leaflet map plot(samp_cap, locagrid = TRUE, static = TRUE) ca_example_apireq(4) %>% ca_preflight() #> General issues #>  - none found #> Issues for querying values #>  - none found #> Issues for downloading rasters #>  - none found"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/large-queries.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Large Queries","text":"Suppose project requires get climate data every census track California (8000). maybe need daily projected temperature every school state, multiple emissions scenarios multiple GCMs. ’s lot data, lot API calls. downloading large volumes data, generally want run one command everything , smart enough download data . probably also don’t want lose ’ve already gotten computer crashes internet goes . address challenges, caldaptr allows save queried data local database downloaded. One function start fetching data based API request object, save database, keep going everything downloaded. internet drops turn computer, can just run function pick left . vignette explain use ca_getvals_db() download data local SQLite database, work data either remote tibble SQL expressions, optimize performance database creating indices. TIP: alternative approach getting lot data download Cal-Adapt data rasters, use functions like st_extract() aggregate() query areas--interest. See Rasters Part vignette details.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/large-queries.html","id":"example-query-data-for-450-census-tracks","dir":"Articles","previous_headings":"","what":"Example: Query Data for 450 Census Tracks","title":"Large Queries","text":"example, ’ll get query daily historical temperature data 453 census tracts Riverside County. Start loading required packages: Next, get census tract ids Riverside County. easiest way using built-constant aoipreset_idval, census tracts includes ‘tract’ ids (geoid). census tracts ’re interested start 6065 (‘6’ FIPs code California, ‘065’ FIPs code Riverside County): Next, create API request census tracts mean observed daily air temperature 1980-2010 (.e., Livneh data):   also define SQLite database file go. SQLite database single file, typically extension .db .sqlite. Ideally go stable location (.e., temp folder removable media) ’ll need keep accessing populate read data analysis. picking directory giving name, don’t anything special. file doesn’t exist first fetch data, created fly. ’ll put sub-directory user’s caladaptr ‘data’ directory.","code":"library(dplyr) library(sf) library(tmap) library(caladaptr) ca_settings(console_colors = \"light\", quiet = TRUE) rvrsde_trcts_int <- aoipreset_idval$censustracts$tract %>%   as.character() %>%   grep(\"^6065\", ., value = TRUE) %>%   as.numeric()  str(rvrsde_trcts_int) #>  num [1:453] 6.07e+09 6.07e+09 6.07e+09 6.07e+09 6.07e+09 ... (rvrsde_tas_liv_cap <- ca_loc_aoipreset(type=\"censustracts\", idfld = \"tract\",                                         idval = rvrsde_trcts_int) %>%   ca_livneh(TRUE) %>%   ca_years(start = 1980, end = 2010) %>%   ca_cvar(c(\"tasmin\", \"tasmax\")) %>%   ca_period(\"day\") %>%   ca_options(spatial_ag = \"mean\")) #> Cal-Adapt API Request #> Location(s):  #>   AOI Preset: censustracts #>   tract(s): 6065030101, 6065030103, 6065030104, (+ 450 more) #> Variable(s): tasmin, tasmax #> Temporal aggregration period(s): day #> Livneh data: TRUE #> Dates: 1980-01-01 to 2010-12-31 #> Options: #>   spatial ag: mean #>   rvrsde_tas_liv_cap %>% ca_preflight() #> General issues #>  - none found #> Issues for querying values #>  - none found #> Issues for downloading rasters #>  - none found  # Omit `static = TRUE` to view an interactive map plot(rvrsde_tas_liv_cap, static = TRUE) ## Create a folder for the database data_dir <- tools::R_user_dir(\"caladaptr\", which = \"data\") (tracts_dir <- file.path(data_dir, \"tracts_liv\") %>% normalizePath(mustWork = FALSE)) #> [1] \"C:\\\\Users\\\\Andy\\\\AppData\\\\Roaming\\\\R\\\\data\\\\R\\\\caladaptr\\\\tracts_liv\" if (!file.exists(tracts_dir)) dir.create(tracts_dir, recursive = TRUE)  ## Define a new SQLite file name rvrsde_liv_tas_fn <- file.path(tracts_dir, \"rvrsde_liv_tas.sqlite\") %>% normalizePath(mustWork = FALSE)"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/large-queries.html","id":"fetch-data","dir":"Articles","previous_headings":"","what":"Fetch Data","title":"Large Queries","text":"Next, fetch data server using ca_getvals_db(). similar fetching data ca_getvals_tbl(), also need give file name SQLite database, name table database values saved. ca_getvals_tbl(), climate variable(s) table must use units. Hence save minimum maximum temperature table, temperature precipitation. lookup_tbls = TRUE argument tells save columns repetitive data (GCM, scenario, spatial aggregation function, etc.) integers joined lookup tables. bit like R’s factor data class, can dramatically reduce size database file. new_recs_only = TRUE tells fetch data isn’t already database (based ‘hash’ API call, saved separate table database).  TIP: Adding debug = TRUE ca_getvals_db() show additional information including many calls required complete request.","code":"rvrsde_liv_tas_rtbl <- rvrsde_tas_liv_cap %>%   ca_getvals_db(db_fn = rvrsde_liv_tas_fn,                 db_tbl = \"rvrsde_tas\",                 lookup_tbls = TRUE,                 new_recs_only = TRUE,                 quiet = TRUE)  rvrsde_liv_tas_rtbl #> # Source:   SQL [?? x 7] #> # Database: sqlite 3.47.1 [C:\\Users\\Andy\\AppData\\Roaming\\R\\data\\R\\caladaptr\\tracts_liv\\rvrsde_liv_tas.sqlite] #>         tract cvar   period slug              spag  dt           val #>       <int64> <chr>  <chr>  <chr>             <chr> <chr>      <dbl> #>  1 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-01  7.41 #>  2 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-02  5.30 #>  3 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-03  5.62 #>  4 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-04  3.57 #>  5 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-05  3.25 #>  6 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-06  7.05 #>  7 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-07  8.45 #>  8 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-08 11.5  #>  9 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-09 11.4  #> 10 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-10 10.9  #> # ℹ more rows"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/large-queries.html","id":"remote-tibbles","dir":"Articles","previous_headings":"","what":"Remote Tibbles","title":"Large Queries","text":"ca_getvals_db() returns remote tibble, can think front-end database part looks acts like regular tibble (exceptions). However values remote tibble held memory, can tell looking size:  print , ’ll notice mostly looks like regular tibble, couple differences. name database given, however number rows isn’t provided prints first rows: Note values ‘gcm’ column columns character, even though ’re saved integers connected lookup tables. hood, remote tibble based SQL expression joins values table lookup tables. Remote tibbles powered backend dbplyr, handles back--forth code database. basic analyses, can use usual functions dplyr, like filter(), group_by(), summarize(), etc. Data database read memory absolutely necessary (.e., comes time print, plot, evaluate input another function, etc.). Note base R functions operators work remote tibbles. Whenever possible, use dplyr version. example grab column: find many rows remote tibble, nrow() doesn’t work can use dplyr::count(): filter() select() work expected. example get just values first tract 1980, can run: compute mean minimum daily temperature census tract, can use group_by() summarize(): every dplyr expression work remote tibbles however. valid R expressions simply don’t SQL counterpart. following statements work regular tibbles remote tibbles. encounter problems like , can either learn SQL find SQL approach objective, convert SQLite table another R data class (like regular tibble, data.table). save convert results dplyr expression new tibble, add collect() end. force read values memory:","code":"rvrsde_liv_tas_rtbl %>% object.size() %>% format(units = \"Mb\") #> [1] \"0 Mb\" rvrsde_liv_tas_rtbl #> # Source:   SQL [?? x 7] #> # Database: sqlite 3.47.1 [C:\\Users\\Andy\\AppData\\Roaming\\R\\data\\R\\caladaptr\\tracts_liv\\rvrsde_liv_tas.sqlite] #>         tract cvar   period slug              spag  dt           val #>       <int64> <chr>  <chr>  <chr>             <chr> <chr>      <dbl> #>  1 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-01  7.41 #>  2 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-02  5.30 #>  3 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-03  5.62 #>  4 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-04  3.57 #>  5 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-05  3.25 #>  6 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-06  7.05 #>  7 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-07  8.45 #>  8 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-08 11.5  #>  9 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-09 11.4  #> 10 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-10 10.9  #> # ℹ more rows ## dplyr pull() works to grab a column of values rvrsde_liv_tas_rtbl %>% pull(tract) %>% unique() %>% length() #> [1] 453  ## The $ operator does not work with remote tibbles :-( ## ERROR: ## rvrsde_liv_tas_rtbl$tract rvrsde_liv_tas_rtbl %>% count() #> # Source:   SQL [?? x 1] #> # Database: sqlite 3.47.1 [C:\\Users\\Andy\\AppData\\Roaming\\R\\data\\R\\caladaptr\\tracts_liv\\rvrsde_liv_tas.sqlite] #>          n #>      <int> #> 1 10258638 rvrsde_liv_tas_rtbl %>%   filter(tract == 6065030101, substring(dt, 1, 4) == \"1980\") %>%   select(dt, val) #> # Source:   SQL [?? x 2] #> # Database: sqlite 3.47.1 [C:\\Users\\Andy\\AppData\\Roaming\\R\\data\\R\\caladaptr\\tracts_liv\\rvrsde_liv_tas.sqlite] #>    dt           val #>    <chr>      <dbl> #>  1 1980-01-01  7.41 #>  2 1980-01-02  5.30 #>  3 1980-01-03  5.62 #>  4 1980-01-04  3.57 #>  5 1980-01-05  3.25 #>  6 1980-01-06  7.05 #>  7 1980-01-07  8.45 #>  8 1980-01-08 11.5  #>  9 1980-01-09 11.4  #> 10 1980-01-10 10.9  #> # ℹ more rows rvrsde_liv_tas_rtbl %>%   filter(tract <= 6065030601) %>%   group_by(tract) %>%   summarize(mean_daily_min = mean(val, na.rm = TRUE)) #> # Source:   SQL [?? x 2] #> # Database: sqlite 3.47.1 [C:\\Users\\Andy\\AppData\\Roaming\\R\\data\\R\\caladaptr\\tracts_liv\\rvrsde_liv_tas.sqlite] #>         tract mean_daily_min #>       <int64>          <dbl> #>  1 6065030101           18.6 #>  2 6065030103           18.7 #>  3 6065030104           18.7 #>  4 6065030200           18.8 #>  5 6065030300           18.8 #>  6 6065030400           18.8 #>  7 6065030501           18.4 #>  8 6065030502           18.4 #>  9 6065030503           18.4 #> 10 6065030601           18.3 ## These expressions do not work with remote tibbles ## rvrsde_liv_tas_rtbl %>% slice(1:500)                                           ## doesn't work  ## all_tracts <- rvrsde_liv_tas_rtbl %>% pull(tract) %>% unique() ## rvrsde_liv_tas_rtbl %>% filter(tract %in% all_tracts[1:50])                    ## doesn't work  ##rvrsde_liv_tas_rtbl %>% filter(tract %in% c(6065047900,6065048100,6065048200))  ## works my_new_tibble <- rvrsde_liv_tas_rtbl %>%   filter(tract == 6065030101, substring(dt, 1, 4) == \"1980\") %>%   select(dt, val) %>%   collect()  str(my_new_tibble) #> tibble [732 × 2] (S3: tbl_df/tbl/data.frame) #>  $ dt : chr [1:732] \"1980-01-01\" \"1980-01-02\" \"1980-01-03\" \"1980-01-04\" ... #>  $ val: num [1:732] 7.41 5.3 5.62 3.57 3.25 ..."},{"path":"https://ucanr-igis.github.io/caladaptr/articles/large-queries.html","id":"mounting-an-existing-sqlite-database-as-a-remote-tibble","dir":"Articles","previous_headings":"Remote Tibbles","what":"Mounting an existing SQLite database as a remote tibble","title":"Large Queries","text":"start new R session, ’ll need reestablish connection SQLite database order work data remote tibble. database created ca_getvals_db(), can re-load ‘mount’ remote tibble ca_db_read(), passing name SQLite database.","code":"rvrsde_liv_tas_fn #> [1] \"C:\\\\Users\\\\Andy\\\\AppData\\\\Roaming\\\\R\\\\data\\\\R\\\\caladaptr\\\\tracts_liv\\\\rvrsde_liv_tas.sqlite\" x_tbl <- ca_db_read(rvrsde_liv_tas_fn) x_tbl #> # Source:   SQL [?? x 7] #> # Database: sqlite 3.47.1 [C:\\Users\\Andy\\AppData\\Roaming\\R\\data\\R\\caladaptr\\tracts_liv\\rvrsde_liv_tas.sqlite] #>         tract cvar   period slug              spag  dt           val #>       <int64> <chr>  <chr>  <chr>             <chr> <chr>      <dbl> #>  1 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-01  7.41 #>  2 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-02  5.30 #>  3 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-03  5.62 #>  4 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-04  3.57 #>  5 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-05  3.25 #>  6 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-06  7.05 #>  7 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-07  8.45 #>  8 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-08 11.5  #>  9 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-09 11.4  #> 10 6065030101 tasmin day    tasmin_day_livneh mean  1980-01-10 10.9  #> # ℹ more rows"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/large-queries.html","id":"reading-databases-with-sql","dir":"Articles","previous_headings":"","what":"Reading databases with SQL","title":"Large Queries","text":"aren’t limited interacting SQLite databases via remote tibbles, don’t need caladaptr functions access . can connect directly, read / edit data using SQL. SQL powerful flexible language working relational databases, supported R DBI package. help write SQL statements, ca_db_info() show ’s SQLite database created ca_getvals_db(). can pass name SQLite database file, remote tibble created ca_getvals_db(), ca_db_info(). output includes tables, fields, primary keys, indices database. also show SQL expression primary data table(s) lookup tables used. SQL beyond scope vignette, example using DBI send SQL statements SQLite database query table. See documentation DBI SQLite Tutorial information examples. TIP: SQL/SQLite dplyr/R good different things. Databases good way save large amounts tabular data, SQL works pretty well filter rows, join tables, compute simple summaries. dplyr/tidyverse/R good reshaping data, complex summaries, integration packages methods. hit wall analysis, think can mix match SQL dplyr leverage strengths .","code":"rvrsde_liv_tas_fn %>% ca_db_info() #> Cal-Adapt Query Database #> Source: C:\\Users\\Andy\\AppData\\Roaming\\R\\data\\R\\caladaptr\\tracts_liv\\rvrsde_liv_tas.sqlite #>  #> Cal-Adapt data tables: #>  rvrsde_tas #>    - Fields: tract; cvar_id; period_id; slug_id; spag_id; dt; val #>    - Num rows: 10258638 #>    - Indices: rvrsde_tas.tract #>    - SQL: SELECT tract, cvar, period, slug, spag, dt, val FROM rvrsde_tas LEFT JOIN cvars ON rvrsde_tas.cvar_id = cvars.cvar_id LEFT JOIN periods ON rvrsde_tas.period_id = periods.period_id LEFT JOIN slugs ON rvrsde_tas.slug_id = slugs.slug_id LEFT JOIN spags ON rvrsde_tas.spag_id = spags.spag_id #>  #> Lookup tables: #>  cvars #>    - Fields: cvar_id*; cvar #>    - Num rows: 11 #>    - Indices: none #>  #>  periods #>    - Fields: period_id*; period #>    - Num rows: 4 #>    - Indices: none #>  #>  slugs #>    - Fields: slug_id*; slug #>    - Num rows: 2 #>    - Indices: none #>  #>  spags #>    - Fields: spag_id*; spag #>    - Num rows: 6 #>    - Indices: none #>  #> API Request Hashes Tables: #>  rvrsde_tas_hashes #>    - Fields: hash_int* #>    - Num rows: 906 #>    - Indices: none #>  #> library(DBI); library(RSQLite)  ## Grab the active database connection. ## db_conn <- rvrsde_liv_tas_rtbl$src$con  ## If there wasn't an active connection, we could open one directly with db_conn <- dbConnect(SQLite(), dbname = rvrsde_liv_tas_fn)  ## List the tables dbListTables(db_conn) #> [1] \"cvars\"             \"periods\"           \"rvrsde_tas\"        \"rvrsde_tas_hashes\" \"slugs\"             \"spags\"  ## Import one table in its entirety (dbReadTable(db_conn, \"slugs\")) #>   slug_id              slug #> 1       1 tasmin_day_livneh #> 2       2 tasmax_day_livneh  ## Use a SELECT query to read the first 12 records from rvrsde_tas first12_qry <- dbSendQuery(db_conn, \"SELECT * FROM rvrsde_tas LIMIT 12;\") (first12_tbl <- dbFetch(first12_qry)) #>         tract cvar_id period_id slug_id spag_id         dt    val #> 1  6065030101       2         1       1       2 1980-01-01  7.415 #> 2  6065030101       2         1       1       2 1980-01-02  5.295 #> 3  6065030101       2         1       1       2 1980-01-03  5.620 #> 4  6065030101       2         1       1       2 1980-01-04  3.575 #> 5  6065030101       2         1       1       2 1980-01-05  3.250 #> 6  6065030101       2         1       1       2 1980-01-06  7.050 #> 7  6065030101       2         1       1       2 1980-01-07  8.450 #> 8  6065030101       2         1       1       2 1980-01-08 11.460 #> 9  6065030101       2         1       1       2 1980-01-09 11.380 #> 10 6065030101       2         1       1       2 1980-01-10 10.935 #> 11 6065030101       2         1       1       2 1980-01-11 11.345 #> 12 6065030101       2         1       1       2 1980-01-12 13.175 dbClearResult(first12_qry)  ## Get the mean and standard deviation of tasmax by tract and year tract_yr_tasmax_qry <- dbSendQuery(db_conn, \"SELECT tract, cvar, substr(dt, 1, 4) as year,                                    avg(val) as avg_val, stdev(val) as sd_val                                    FROM rvrsde_tas LEFT JOIN cvars ON rvrsde_tas.cvar_id = cvars.cvar_id                                    WHERE cvar = 'tasmax'                                    GROUP BY tract, substr(dt, 1, 4)                                    LIMIT 40;\") (tract_yr_tasmax_tbl <- dbFetch(tract_yr_tasmax_qry)) #>         tract   cvar year  avg_val   sd_val #> 1  6065030101 tasmax 1980 26.21607 6.852663 #> 2  6065030101 tasmax 1981 26.34479 7.350711 #> 3  6065030101 tasmax 1982 23.53210 7.387218 #> 4  6065030101 tasmax 1983 25.14408 7.513801 #> 5  6065030101 tasmax 1984 26.83633 7.069716 #> 6  6065030101 tasmax 1985 25.93858 7.863726 #> 7  6065030101 tasmax 1986 26.52530 6.510764 #> 8  6065030101 tasmax 1987 25.36882 7.144761 #> 9  6065030101 tasmax 1988 26.46512 7.067632 #> 10 6065030101 tasmax 1989 26.54858 7.057848 #> 11 6065030101 tasmax 1990 26.55011 7.615560 #> 12 6065030101 tasmax 1991 26.15068 6.723376 #> 13 6065030101 tasmax 1992 26.40520 7.267906 #> 14 6065030101 tasmax 1993 25.93308 6.787862 #> 15 6065030101 tasmax 1994 26.03052 7.195865 #> 16 6065030101 tasmax 1995 26.25166 7.524154 #> 17 6065030101 tasmax 1996 26.99464 7.454512 #> 18 6065030101 tasmax 1997 27.09871 7.136586 #> 19 6065030101 tasmax 1998 25.47475 7.428966 #> 20 6065030101 tasmax 1999 26.48893 6.935570 #> 21 6065030101 tasmax 2000 27.02283 6.932329 #> 22 6065030101 tasmax 2001 26.40905 7.781031 #> 23 6065030101 tasmax 2002 26.80597 6.768257 #> 24 6065030101 tasmax 2003 27.23386 7.296919 #> 25 6065030101 tasmax 2004 26.89044 7.072354 #> 26 6065030101 tasmax 2005 26.25752 7.259982 #> 27 6065030101 tasmax 2006 27.78707 7.590995 #> 28 6065030101 tasmax 2007 27.32666 7.516599 #> 29 6065030101 tasmax 2008 26.72738 7.864197 #> 30 6065030101 tasmax 2009 27.45423 7.349510 #> 31 6065030101 tasmax 2010 26.02900 7.585175 #> 32 6065030103 tasmax 1980 26.28562 6.856170 #> 33 6065030103 tasmax 1981 26.45149 7.315280 #> 34 6065030103 tasmax 1982 23.77380 7.349562 #> 35 6065030103 tasmax 1983 25.21624 7.458894 #> 36 6065030103 tasmax 1984 26.99472 7.132914 #> 37 6065030103 tasmax 1985 26.03365 7.810316 #> 38 6065030103 tasmax 1986 26.61862 6.484041 #> 39 6065030103 tasmax 1987 25.53032 7.147122 #> 40 6065030103 tasmax 1988 26.58549 7.030189 dbClearResult(tract_yr_tasmax_qry)"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/large-queries.html","id":"optimizating-database-performance","dir":"Articles","previous_headings":"","what":"Optimizating Database Performance","title":"Large Queries","text":"Two aspects database optimization managing size database disk, speed querying data. general considerations managing aspects SQLite databases.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/large-queries.html","id":"how-many-databases","dir":"Articles","previous_headings":"Optimizating Database Performance","what":"How many databases?","title":"Large Queries","text":"save data database ca_getvals_db(), get choose much data put single table, many tables put one database, many databases create. general guidelines many databases use: SQLite databases contained single file, can hold many tables. However little performance gain multiple tables single database (aside lookup tables), compared separate databases. may also performance hit multiple large tables database. Also need access simultaneously, may manage connections (.e., dbplyr may limit number parallel connections queries single database). end spectrum, generally don’t want lots database connections open simultaneously. Even don’t see connections (dbplyr manages ), database requires ’s connection, takes bit overhead. access database files loop, sure delete remote tibbles manually close connections don’t accumulate.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/large-queries.html","id":"how-many-tables","dir":"Articles","previous_headings":"Optimizating Database Performance","what":"How many tables?","title":"Large Queries","text":"terms much data put one table, general points consider: Databases like SQLite designed handle millions records, ’s ’re designed . ’s unlikely reach technical limits database can handle. general guide, aim data analysis summary single table. example need minimum maximum temperature analysis (maybe compute growing degree days), put values table. perform better retrieving data two different tables, combining R. exception rule data can’t combined single table technical reasons. example following types data generally can’t combined table: Livneh non-Livneh data (different columns) climate variables different units (e.g., windspeed precipitation) general rule, large tables can slower query smaller tables (although can improved indices, see ). Thus get data single analysis single table, start new table next batch data. TIP: doubt, save one dataset one data table, one data table one database. Delete remote tibbles longer need free database connections.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/large-queries.html","id":"indices","dir":"Articles","previous_headings":"Optimizating Database Performance","what":"Indices","title":"Large Queries","text":"can create indices specific fields specific tables. Indices like phone book field, improve speed operations utilize field (filters joins). downside indices increase size database disk. general good practice create indices fields expect use joins, filters, sorting (including location id field), others. info, see documentation SQLite.org. can create indices passing field name(s) indices argument first populate table ca_getvals_db(). downside slightly slower write speed, index updated every time data written table. database created, additional data brought via ca_getvals_db() automatically indexed, additional indices can created indices argument. alternative approach skip indices downloading, instead add data downloaded, start analysis. can see fields indices using ca_db_info() (), directly using functions DBI. can add delete indices existing database using ca_db_indices(). example add index ‘tract’ column (speed filters joins column), run: TIP: might want wait see slow analyses deciding create indices, increase size database. wait time tolerable, don’t run summary often, adding indices may necessary.","code":"rvrsde_liv_tas_rtbl %>%   ca_db_indices(tbl = \"rvrsde_tas\", idx_fld_add = \"tract\") %>%   ca_db_info() #> rvrsde_tas.tract is already indexed, skipping #> No indices added #> No indices deleted #> Cal-Adapt Query Database #> Source: C:/Users/Andy/AppData/Roaming/R/data/R/caladaptr/tracts_liv/rvrsde_liv_tas.sqlite #>  #> Cal-Adapt data tables: #>  rvrsde_tas #>    - Fields: tract; cvar_id; period_id; slug_id; spag_id; dt; val #>    - Num rows: 10258638 #>    - Indices: rvrsde_tas.tract #>    - SQL: SELECT tract, cvar, period, slug, spag, dt, val FROM rvrsde_tas LEFT JOIN cvars ON rvrsde_tas.cvar_id = cvars.cvar_id LEFT JOIN periods ON rvrsde_tas.period_id = periods.period_id LEFT JOIN slugs ON rvrsde_tas.slug_id = slugs.slug_id LEFT JOIN spags ON rvrsde_tas.spag_id = spags.spag_id #>  #> Lookup tables: #>  cvars #>    - Fields: cvar_id*; cvar #>    - Num rows: 11 #>    - Indices: none #>  #>  periods #>    - Fields: period_id*; period #>    - Num rows: 4 #>    - Indices: none #>  #>  slugs #>    - Fields: slug_id*; slug #>    - Num rows: 2 #>    - Indices: none #>  #>  spags #>    - Fields: spag_id*; spag #>    - Num rows: 6 #>    - Indices: none #>  #> API Request Hashes Tables: #>  rvrsde_tas_hashes #>    - Fields: hash_int* #>    - Num rows: 906 #>    - Indices: none #>  #>"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/large-queries.html","id":"reducing-the-number-of-api-calls-by-grouping-locations-by-loca-grid-cell","dir":"Articles","previous_headings":"Optimizating Database Performance","what":"Reducing the Number of API Calls by Grouping Locations by Loca Grid Cell","title":"Large Queries","text":"LOCA grid cells approximately 6km (3.7 mi) side. locations within grid cell therefore values LOCA downscaled climate variables, projected historic, modeled observed. one point location per grid cell, doesn’t make sense query server one ’ll return values. provides way reduce number total calls server. next example, ’ll get climate data schools CA (10,000). many schools, many close together (especially cities), ’ll first spatial join LOCA grid. Next ’ll take grids schools , find centroids, create API request object centroids, fetch data. can join results back schools LOCA grid id. First import schools get California Department Education GeoHub:   Next, import LOCA grid: illustrate distribution points relative LOCA grid cells, can overlay zoomed area central valley:  Next, spatial join points LOCA grid cells. end result new column id schools layer, id number LOCA grid cell falls : Next, grab unique values id column: means instead 10,043 locations, query 1,624. ’s pretty big savings, particularly considering example location requires 4 API calls (one GCM). Next create point layer 1,624 LOCA grid cells contain schools. pass grid cells polygons, passing points means don’t worry Cal-Adapt server getting values adjacent cells, don’t specify spatial aggregation function. Next, create API request. ’ll get monthly evapotranspiration end century: Next, fetch data. still lot locations, ’ll use ca_getvals_db() save database: Suppose analysis calls mean ET years GCMs combined. can generate metric LOCA grid : can now join summary ET LOCA grid cell back schools layer, using grid id join field.","code":"library(sf) ca_schools_url <- \"https://raw.githubusercontent.com/ucanr-igis/caladaptr-res/main/geoms/ca_schools.geojson\" ca_schools_sf <- st_read(ca_schools_url, quiet = TRUE) dim(ca_schools_sf) #> [1] 10043     4 ca_schools_sf #> Simple feature collection with 10043 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -124.2856 ymin: 32.54807 xmax: -114.3958 ymax: 41.98865 #> Geodetic CRS:  WGS 84 #> First 10 features: #>    OBJECTID                              SchoolName       SchoolType                   geometry #> 1         1  Envision Academy for Arts & Technology             High POINT (-122.2684 37.80468) #> 2         2 Community School for Creative Education       Elementary POINT (-122.2386 37.78464) #> 3         3                         Yu Ming Charter       Elementary POINT (-122.2836 37.84737) #> 4         4                Urban Montessori Charter       Elementary  POINT (-122.188 37.78676) #> 5         5                            Epic Charter           Middle POINT (-122.2296 37.77711) #> 6         6      Alameda County Juvenile Hall/Court   Juvenile Court POINT (-122.1182 37.71595) #> 7         7                Alameda County Community County Community POINT (-122.0979 37.65835) #> 8         8                    Oakland Unity Middle           Middle POINT (-122.1908 37.75908) #> 9         9    Connecting Waters Charter - East Bay             K-12 POINT (-122.0251 37.60378) #> 10       10                     Opportunity Academy County Community POINT (-122.0979 37.65835) tm_shape(ca_schools_sf) + tm_dots(col = \"gray\") (locagrid_sf <- ca_locagrid_geom()) #> Reading layer `locagrid' from data source `C:\\Users\\Andy\\AppData\\Local\\R\\cache\\R\\caladaptr\\locagrid.gpkg' using driver `GPKG' #> Simple feature collection with 26517 features and 1 field #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: -124.5625 ymin: 31.5625 xmax: -113.375 ymax: 43.75 #> Geodetic CRS:  WGS 84 #> Simple feature collection with 26517 features and 1 field #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: -124.5625 ymin: 31.5625 xmax: -113.375 ymax: 43.75 #> Geodetic CRS:  WGS 84 #> First 10 features: #>       id                           geom #> 1  23693 POLYGON ((-124.1875 43.75, ... #> 2  23694 POLYGON ((-124.125 43.75, -... #> 3  23695 POLYGON ((-124.0625 43.75, ... #> 4  23696 POLYGON ((-124 43.75, -123.... #> 5  23697 POLYGON ((-123.9375 43.75, ... #> 6  23698 POLYGON ((-123.875 43.75, -... #> 7  23699 POLYGON ((-123.8125 43.75, ... #> 8  23700 POLYGON ((-123.75 43.75, -1... #> 9  23701 POLYGON ((-123.6875 43.75, ... #> 10 23702 POLYGON ((-123.625 43.75, -... tm_shape(ca_schools_sf, bbox = c(-121.0896, 37.56298, -120.38750, 38.17253)) +   tm_dots(col = \"#333333\") + tm_shape(locagrid_sf) +   tm_borders(col = \"#0080c0\") #> Warning: Current projection unknown. Long lat coordinates (wgs84) assumed. ca_schools_loca_sf <- ca_schools_sf %>% st_join(locagrid_sf) ca_schools_loca_sf %>% st_drop_geometry() %>% head() #>   OBJECTID                              SchoolName     SchoolType    id #> 1        1  Envision Academy for Arts & Technology           High 39897 #> 2        2 Community School for Creative Education     Elementary 39898 #> 3        3                         Yu Ming Charter     Elementary 39750 #> 4        4                Urban Montessori Charter     Elementary 39898 #> 5        5                            Epic Charter         Middle 39898 #> 6        6      Alameda County Juvenile Hall/Court Juvenile Court 40047 loca_ids_schools <- ca_schools_loca_sf %>% pull(id) %>% unique() str(loca_ids_schools) #>  int [1:1624] 39897 39898 39750 40047 40191 40337 40046 40486 40045 40044 ... loca_ctr_sf <- locagrid_sf %>%   filter(id %in% loca_ids_schools) %>%   st_centroid() #> Warning: st_centroid assumes attributes are constant over geometries loca_ctr_sf %>% head() #> Simple feature collection with 6 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -124.1563 ymin: 41.90625 xmax: -120.2812 ymax: 41.96875 #> Geodetic CRS:  WGS 84 #>      id                       geom #> 1 28679 POINT (-121.9063 41.96875) #> 2 28686 POINT (-121.4687 41.96875) #> 3 28705 POINT (-120.2812 41.96875) #> 4 28817 POINT (-124.1563 41.90625) #> 5 28843 POINT (-122.5312 41.90625) #> 6 28846 POINT (-122.3437 41.90625) locaschl_et_cap <- ca_loc_sf(loc = loca_ctr_sf, idfld = \"id\") %>%   ca_gcm(gcms[1:4]) %>%   ca_scenario(\"rcp85\") %>%   ca_cvar(\"et\") %>%   ca_period(\"month\") %>%   ca_years(start = 2080, end = 2099)  locaschl_et_cap %>% ca_preflight() #> General issues #>  - none found #> Issues for querying values #>  - none found #> Issues for downloading rasters #>  - none found data_dir <- tools::R_user_dir(\"caladaptr\", which = \"data\") schools_dir <- file.path(data_dir, \"schools\") %>% normalizePath(mustWork = FALSE) if (!file.exists(schools_dir)) dir.create(schools_dir, recursive = TRUE)  ## Define a new SQLite file name locaschl_fn <- file.path(schools_dir, \"loca_schl.sqlite\") %>% normalizePath(mustWork = FALSE)  ## Fetch data locaschl_et_rtbl <- locaschl_et_cap %>%   ca_getvals_db(db_fn = locaschl_fn, db_tbl = \"locaschl_et\", new_recs_only = TRUE, quiet = TRUE)  head(locaschl_et_rtbl) #> # Source:   SQL [?? x 8] #> # Database: sqlite 3.47.1 [C:\\Users\\Andy\\AppData\\Roaming\\R\\data\\R\\caladaptr\\schools\\loca_schl.sqlite] #>      id cvar  scenario gcm        period spag  dt           val #>   <int> <chr> <chr>    <chr>      <chr>  <chr> <chr>      <dbl> #> 1 28679 et    rcp85    HadGEM2-ES month  none  2080-01-31 0.626 #> 2 28679 et    rcp85    HadGEM2-ES month  none  2080-02-29 0.870 #> 3 28679 et    rcp85    HadGEM2-ES month  none  2080-03-31 1.75  #> 4 28679 et    rcp85    HadGEM2-ES month  none  2080-04-30 2.82  #> 5 28679 et    rcp85    HadGEM2-ES month  none  2080-05-31 3.05  #> 6 28679 et    rcp85    HadGEM2-ES month  none  2080-06-30 2.09 locaschl_meanet_tbl <- locaschl_et_rtbl %>%   group_by(id) %>%   summarise(mean_et = mean(val, na.rm = TRUE)) %>%   collect()  locaschl_meanet_tbl %>% head() #> # A tibble: 6 × 2 #>      id mean_et #>   <int>   <dbl> #> 1 28679   1.02  #> 2 28686   0.802 #> 3 28705   1.77  #> 4 28817   2.18  #> 5 28843   1.19  #> 6 28846   1.41 ca_schools_et_sf <- ca_schools_loca_sf %>%   left_join(locaschl_meanet_tbl, by = \"id\")  ca_schools_et_sf %>% head() #> Simple feature collection with 6 features and 5 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -122.2836 ymin: 37.71595 xmax: -122.1182 ymax: 37.84737 #> Geodetic CRS:  WGS 84 #>   OBJECTID                              SchoolName     SchoolType    id   mean_et                   geometry #> 1        1  Envision Academy for Arts & Technology           High 39897 0.5725853 POINT (-122.2684 37.80468) #> 2        2 Community School for Creative Education     Elementary 39898 0.4645488 POINT (-122.2386 37.78464) #> 3        3                         Yu Ming Charter     Elementary 39750 0.4560700 POINT (-122.2836 37.84737) #> 4        4                Urban Montessori Charter     Elementary 39898 0.4645488  POINT (-122.188 37.78676) #> 5        5                            Epic Charter         Middle 39898 0.4645488 POINT (-122.2296 37.77711) #> 6        6      Alameda County Juvenile Hall/Court Juvenile Court 40047 1.0476258 POINT (-122.1182 37.71595)"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"great deal climate data, including bulk data Cal-Adapt, inherently raster. x y dimensions represent space, third dimension represents time, values ‘cells’ represent climate variable like maximum temperature. Raster data can challenging work querying values specific location, files can large need special tools work . However working large areas, analysis calls something ---box, getting data rasters may way go. three commonly used ways download raster data Cal-Adapt: NetCDF files full extent LOCA downscaled data available download Cal-Adapt Data Server. NetCDF files discussed (see Part III). Rasters can downloaded specific variables areas--interest using Cal-Adapt Data Download Tool. Rasters can requested programmatically Cal-Adapt API. Downloading rasters relatively easy caladaptr. API request object use query values can used download rasters passing ca_getrst_stars(). function saves rasters disk TIF files, additional ‘sidecar’ files store additional metadata TIF format can’t handle. analysis, next import TIFs R ca_stars_read(), come ‘stars’ objects. , can use functions stars package, well-equipped handle spatiotemporal arrays raster data. rest vignette demonstrates download work Cal-Adapt data rasters. first 20% actually involves functions caladpatr. rest tutorial, bulk work flows, use functions stars combine, subset, analyze Cal-Adapt raster data.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"download-practice-data","dir":"Articles","previous_headings":"","what":"Download Practice Data","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"illustrate, ’ll download 20 years daily temperature data Merced County 4 GCMs 2 emissions scenarios. Start loading packages ’ll need: FIPs code Merced County “06047”1. always first create API request: Note: normally construct API request object polygon features, ’re supposed include ca_options() specify want spatially aggregate climate values. optional (fact ignored) downloading rasters, spatially aggregating anything. (example spatially aggregating raster data ’s downloaded, see Part III.) ’s generally good idea plot API request using ensure ’ve got right area:  looks good. Next let’s download data TIFs passing merced_cap ca_getrst_stars(). function two important things: downloads data saves standard TIFs out_dir, creates little ‘sidecar’ file TIF saves additional metadata TIF (GCM emissions scenario). can see downloaded. Note TIF sidecar rds file additional metadata:  useful arguments ca_getrst_stars() include: mask = TRUE area interest polygon, pixels outside area interest given NA values multiple locations API request, merge_geoms = TRUE merge geoms together return single TIF covers locations (assuming ’re far apart extent union small enough queried Cal-Adapt API). See also vignette downloading rasters large areas. overwrite = FALSE tells ca_getrst_stars() first see TIF file already downloaded (based automatically generated file name). can help re-run code quickly files won’t re-downloaded time. TIP: Managing downloaded TIF files. way import Cal-Adapt data R rasters without first downloading TIF files. help manage potentially large numbers downloaded TIF files, good practice create separate data directories location project, use out_dir argument put downloaded files need . desire keep TIF files, can download tempdir() delete programatically unlink() (remember get rds files also).","code":"library(caladaptr) library(dplyr) library(sf) library(stars) library(magrittr) library(ggplot2) library(lubridate) merced_cap <- ca_loc_aoipreset(type = \"counties\", idfld = \"fips\", idval = \"06047\") %>%   ca_gcm(gcms[1:4]) %>%   ca_period(\"day\") %>%   ca_cvar(c(\"tasmin\", \"tasmax\")) %>%   ca_scenario(c(\"rcp45\", \"rcp85\")) %>%   ca_years(start = 2045, end = 2065) plot(merced_cap, locagrid = TRUE, static = TRUE) data_dir <- tools::R_user_dir(\"caladaptr\", which = \"data\") merced_dir <- file.path(data_dir, \"merced\") if (!file.exists(merced_dir)) dir.create(merced_dir, recursive = TRUE)  merced_stars_fn <- merced_cap %>%   ca_getrst_stars(out_dir = merced_dir, mask = TRUE, quiet = TRUE,                   normalize_path = TRUE, overwrite = FALSE) list.files(merced_dir) #>  [1] \"mercd_bos_dist.geojson\"                          \"tasmax_day_CanESM2_rcp45_fips-06047.attr.rds\"    #>  [3] \"tasmax_day_CanESM2_rcp45_fips-06047.tif\"         \"tasmax_day_CanESM2_rcp85_fips-06047.attr.rds\"    #>  [5] \"tasmax_day_CanESM2_rcp85_fips-06047.tif\"         \"tasmax_day_CNRM-CM5_rcp45_fips-06047.attr.rds\"   #>  [7] \"tasmax_day_CNRM-CM5_rcp45_fips-06047.tif\"        \"tasmax_day_CNRM-CM5_rcp85_fips-06047.attr.rds\"   #>  [9] \"tasmax_day_CNRM-CM5_rcp85_fips-06047.tif\"        \"tasmax_day_HadGEM2-ES_rcp45_fips-06047.attr.rds\" #> [11] \"tasmax_day_HadGEM2-ES_rcp45_fips-06047.tif\"      \"tasmax_day_HadGEM2-ES_rcp85_fips-06047.attr.rds\" #> [13] \"tasmax_day_HadGEM2-ES_rcp85_fips-06047.tif\"      \"tasmax_day_MIROC5_rcp45_fips-06047.attr.rds\"     #> [15] \"tasmax_day_MIROC5_rcp45_fips-06047.tif\"          \"tasmax_day_MIROC5_rcp85_fips-06047.attr.rds\"     #> [17] \"tasmax_day_MIROC5_rcp85_fips-06047.tif\"          \"tasmin_day_CanESM2_rcp45_fips-06047.attr.rds\"    #> [19] \"tasmin_day_CanESM2_rcp45_fips-06047.tif\"         \"tasmin_day_CanESM2_rcp85_fips-06047.attr.rds\"    #> [21] \"tasmin_day_CanESM2_rcp85_fips-06047.tif\"         \"tasmin_day_CNRM-CM5_rcp45_fips-06047.attr.rds\"   #> [23] \"tasmin_day_CNRM-CM5_rcp45_fips-06047.tif\"        \"tasmin_day_CNRM-CM5_rcp85_fips-06047.attr.rds\"   #> [25] \"tasmin_day_CNRM-CM5_rcp85_fips-06047.tif\"        \"tasmin_day_HadGEM2-ES_rcp45_fips-06047.attr.rds\" #> [27] \"tasmin_day_HadGEM2-ES_rcp45_fips-06047.tif\"      \"tasmin_day_HadGEM2-ES_rcp85_fips-06047.attr.rds\" #> [29] \"tasmin_day_HadGEM2-ES_rcp85_fips-06047.tif\"      \"tasmin_day_MIROC5_rcp45_fips-06047.attr.rds\"     #> [31] \"tasmin_day_MIROC5_rcp45_fips-06047.tif\"          \"tasmin_day_MIROC5_rcp85_fips-06047.attr.rds\"     #> [33] \"tasmin_day_MIROC5_rcp85_fips-06047.tif\""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"read-tifs-into-r","dir":"Articles","previous_headings":"","what":"Read TIFs into R","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"object returned ca_getrst_stars() vector TIF file names. easiest recommended way work rasters R import TIFs ca_read_stars(). can read whole bunch TIFs function passing vector TIF file names. ca_read_stars() returns list stars objects attributed additional metadata Cal-Adapt: Note: stars objects read memory default. rasters really large, /getting lot climate variables, ways controlling gets loaded . Passing proxy = TRUE ca_stars_read() create list ‘stars proxy’ objects, just like stars objects reading data disk postponed needed. See stars documentation details. Let’s look elements stars list: can see list contains 16 stars objects different combos GCM, emissions scenario, climate variable.  simplicity, rest vignette just use one two stars objects. Normally ’d want work rasters, may involve writing code loops work list stars objects. ’ll see generate index stars objects make code loops little easier. Part II introduce even better way processing multiple stars objects combining single six-dimensional climate data cube.","code":"mercd_stars_lst <- merced_stars_fn %>% ca_stars_read() class(mercd_stars_lst) #> [1] \"list\" length(mercd_stars_lst) #> [1] 16 names(mercd_stars_lst) #>  [1] \"tasmin_day_HadGEM2-ES_rcp45_fips-06047\" \"tasmax_day_HadGEM2-ES_rcp45_fips-06047\" \"tasmin_day_CNRM-CM5_rcp45_fips-06047\"   #>  [4] \"tasmax_day_CNRM-CM5_rcp45_fips-06047\"   \"tasmin_day_CanESM2_rcp45_fips-06047\"    \"tasmax_day_CanESM2_rcp45_fips-06047\"    #>  [7] \"tasmin_day_MIROC5_rcp45_fips-06047\"     \"tasmax_day_MIROC5_rcp45_fips-06047\"     \"tasmin_day_HadGEM2-ES_rcp85_fips-06047\" #> [10] \"tasmax_day_HadGEM2-ES_rcp85_fips-06047\" \"tasmin_day_CNRM-CM5_rcp85_fips-06047\"   \"tasmax_day_CNRM-CM5_rcp85_fips-06047\"   #> [13] \"tasmin_day_CanESM2_rcp85_fips-06047\"    \"tasmax_day_CanESM2_rcp85_fips-06047\"    \"tasmin_day_MIROC5_rcp85_fips-06047\"     #> [16] \"tasmax_day_MIROC5_rcp85_fips-06047\""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"explore-a-stars-object","dir":"Articles","previous_headings":"","what":"Explore a stars object","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"Let’s look properties first stars object list: see stars object 3 dimensions. first two columns (x) rows (y), third one date. general, layers rasters downloaded Cal-Adapt represent different time periods. case, asked daily temperature data, 7670 layers represents temperature one day. values cells minimum daily temperature (tasmin). ’s another stars object somewhere list corresponding daily maximum temperature (tasmax). Let’s look cell values first stars object. can use [[]] notation get values ith attribute stars object (stars objects one attribute [[1]] works). TIP: prefer dplyr functions, can use pull(1) instead second [[]] get values. mode() tells us values element (pixel) numeric (R’s data type double precision numbers). summary() reports quantiles. numbers degrees Kelvin, known reading Cal-Adapt documentation. lot NA’s told mask data, pixel lies outside boundary Merced County full NAs.","code":"mercd_stars_lst[[1]] #> stars object with 3 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>                                     Min.  1st Qu.   Median    Mean  3rd Qu.     Max.  NA's #> tasmin_day_HadGEM2-ES_rcp45...  266.4809 280.8343 285.1293 284.897 289.0701 302.3545 58748 #> dimension(s): #>      from   to     offset   delta refsys point x/y #> x       1   20     -121.2  0.0625 WGS 84 FALSE [x] #> y       1   16      37.69 -0.0625 WGS 84 FALSE [y] #> date    1 7670 2045-01-01  1 days   Date    NA mercd_stars_lst[[1]][[1]] %>% mode() #> [1] \"numeric\" mercd_stars_lst[[1]][[1]] %>% summary() #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's  #>   263.7   279.6   284.2   284.3   289.1   306.7 1441960 # mercd_stars_lst[[1]] %>% pull(1) %>% summary()"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"subsetting-stars-objects","dir":"Articles","previous_headings":"","what":"Subsetting stars objects","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"go , need talk subsetting stars objects. ’ve already subsetting list stars objects using standard R list notation (e.g., mercd_stars_lst[[1]]). helps us grab individual stars object interest. stars objects can also subsetted. ’s helpful remember stars objects essentially lists arrays. arrays two-dimensional, like traditional raster, 3 dimensions. ’ve already seen 3-dimensional stars object, third dimension time. Subsetting stars objects along dimensions common step analysis. Fortunately, dimensions stars objects named (e.g., x, y, date). Hence subset along dimensions, can write filter expressions use name dimension make readable (e.g., date > .Date(\"2050-01-01\")) can subset stars objects dplyr verbs filter() slice(). example just wanted select 3 rows 3 columns, pass integers slice(). Note however need tell dimensions ’re slicing, using along argument: filter() works similarly slice(), uses logical values (commonly expression generates logical values), rather indices. wanted subset data just values January 2055, add filter expression: see example subsetting dplyr verbs . One caveat subsetting dplyr may work stars object one row column. Part II show examples subsetting square bracket notation, alternative dplyr verbs.","code":"mercd_stars_lst[[1]] %>%   slice(10:12, along = \"x\") %>%   slice(7:10, along = \"y\") #> stars object with 3 dimensions and 1 attribute #> attribute(s): #>                                     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. #> tasmin_day_HadGEM2-ES_rcp45...  263.7848 279.8704 284.5147 284.5306 289.4701 300.6826 #> dimension(s): #>      from   to     offset   delta refsys point x/y #> x      10   12     -121.2  0.0625 WGS 84 FALSE [x] #> y       7   10      37.69 -0.0625 WGS 84 FALSE [y] #> date    1 7670 2045-01-01  1 days   Date    NA mercd_stars_lst[[1]] %>%   slice(10:12, along = \"x\") %>%   slice(7:10, along = \"y\") %>%   filter(date >= as.Date(\"2055-01-01\"), date <= as.Date(\"2055-01-31\")) #> stars object with 3 dimensions and 1 attribute #> attribute(s): #>                                     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. #> tasmin_day_HadGEM2-ES_rcp45...  268.9576 276.7619 279.2449 278.5362 281.6215 284.0545 #> dimension(s): #>      from to     offset   delta refsys point x/y #> x       1  3     -120.7  0.0625 WGS 84 FALSE [x] #> y       1  4      37.31 -0.0625 WGS 84 FALSE [y] #> date    1 31 2055-01-01  1 days   Date    NA"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"plotting-stars-objects","dir":"Articles","previous_headings":"","what":"Plotting stars objects","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"need big sheet paper plot 7670 layers facets. need either combine values (e.g., take mean pixel), plot small number . Let’s plot first four dates first stars object list. since raster 3 dimensions, tell dimension subsample using along argument. day plotted separately.  TIP: get error message saying ‘figure margins large’, means either plot window small (resize RStudio), stars object ’re trying plot way many layers.","code":"plot(mercd_stars_lst[[1]] %>% slice(index = 1:4, along = \"date\"),      axes = TRUE,      main = attributes(mercd_stars_lst[[1]])$ca_metadata$slug)"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"overlay-a-vector-feature","dir":"Articles","previous_headings":"Plotting stars objects","what":"Overlay a vector feature","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"Overlaying vector layer top plots reassures us right area. Let’s include county boundary plot. First get Merced County boundary using ca_aoipreset_geom(), make sure geographic coordinates (epgs 4326) can overlay : plot together, ’ll use basic plot() function, stars package tailored work stars rasters (including automatic resampling). overlay vector layers using plot(), : add reset = FALSE first plot statement (doesn’t reset axes drawing plot, get little funky legend) include add = TRUE subsequent plot statements","code":"mercd_bnd_sf <- ca_aoipreset_geom(\"counties\", quiet = TRUE) %>%   filter(fips == \"06047\") %>%   st_geometry() %>%   st_transform(4326) plot(mercd_stars_lst[[1]] %>% slice(index = 1, along = \"date\"), axes = TRUE, reset = FALSE) plot(mercd_bnd_sf, border = \"red\", lwd = 2, axes = TRUE, add = TRUE)"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"create-a-list-index","dir":"Articles","previous_headings":"","what":"Create a List Index","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"point list 16 stars objects. help us figure , ’ll create index using ca_index_starslist(). function reads extra metadata stars object (saved sidecare files), returns tibble:","code":"(mercd_stars_tbl <- ca_stars_index(mercd_stars_lst)) #> # A tibble: 16 × 14 #>      idx cvar   units scenario gcm        period slug                        livneh start      end        idfld idval  rows  cols #>    <int> <chr>  <chr> <chr>    <chr>      <chr>  <chr>                       <lgl>  <chr>      <chr>      <chr> <chr> <dbl> <dbl> #>  1     1 tasmin K     rcp45    HadGEM2-ES day    tasmin_day_HadGEM2-ES_rcp45 FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #>  2     2 tasmax K     rcp45    HadGEM2-ES day    tasmax_day_HadGEM2-ES_rcp45 FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #>  3     3 tasmin K     rcp45    CNRM-CM5   day    tasmin_day_CNRM-CM5_rcp45   FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #>  4     4 tasmax K     rcp45    CNRM-CM5   day    tasmax_day_CNRM-CM5_rcp45   FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #>  5     5 tasmin K     rcp45    CanESM2    day    tasmin_day_CanESM2_rcp45    FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #>  6     6 tasmax K     rcp45    CanESM2    day    tasmax_day_CanESM2_rcp45    FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #>  7     7 tasmin K     rcp45    MIROC5     day    tasmin_day_MIROC5_rcp45     FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #>  8     8 tasmax K     rcp45    MIROC5     day    tasmax_day_MIROC5_rcp45     FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #>  9     9 tasmin K     rcp85    HadGEM2-ES day    tasmin_day_HadGEM2-ES_rcp85 FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #> 10    10 tasmax K     rcp85    HadGEM2-ES day    tasmax_day_HadGEM2-ES_rcp85 FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #> 11    11 tasmin K     rcp85    CNRM-CM5   day    tasmin_day_CNRM-CM5_rcp85   FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #> 12    12 tasmax K     rcp85    CNRM-CM5   day    tasmax_day_CNRM-CM5_rcp85   FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #> 13    13 tasmin K     rcp85    CanESM2    day    tasmin_day_CanESM2_rcp85    FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #> 14    14 tasmax K     rcp85    CanESM2    day    tasmax_day_CanESM2_rcp85    FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #> 15    15 tasmin K     rcp85    MIROC5     day    tasmin_day_MIROC5_rcp85     FALSE  2045-01-01 2065-12-31 fips  06047    20    16 #> 16    16 tasmax K     rcp85    MIROC5     day    tasmax_day_MIROC5_rcp85     FALSE  2045-01-01 2065-12-31 fips  06047    20    16"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"subset-the-list-by-gcm-emissions-scenario","dir":"Articles","previous_headings":"Create a List Index","what":"Subset the list by GCM & emissions scenario","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"simplify things, ’ll work temperature data one GCM one emissions scenario. can use index tibble extract indices elements list use GCM scenario: Now can create list stars objects use GCM emissions scenario. point, ’re still just working regular list. ’ll subset list using extract() (magrittr package) equivalent subsetting list []. now list two stars objects. two stars objects spatial area, dates, GCM emission scenario. one tasmin tasmax. goal compute growing degree days, computed (tasmin + tasmax / 2) - basetemp. need get tasmin tasmax stars object new dimension ’ll call ‘cvar’. get single stars object, ’ll ‘merge’ together using c(). stars package provides special version c() adapted combining stars objects. stars c() optional ‘along’ argument, tell want values two stars objects turned another dimension (opposed 2nd attribute). Note appearance new attribute two values. job, can better. next chunk ’ll modify : calling c() part .call (programmatically flexible) programatically create values new dimension, pass named list along tack setNames() end rename attribute something easier eye","code":"(lst_idx <- mercd_stars_tbl %>%   filter(gcm == \"HadGEM2-ES\", scenario == \"rcp45\") %>%   pull(idx)) #> [1] 1 2 one_gcm_scen_lst <- mercd_stars_lst %>% extract(lst_idx) class(one_gcm_scen_lst) #> [1] \"list\" names(one_gcm_scen_lst) #> [1] \"tasmin_day_HadGEM2-ES_rcp45_fips-06047\" \"tasmax_day_HadGEM2-ES_rcp45_fips-06047\" c(one_gcm_scen_lst[[1]], one_gcm_scen_lst[[2]], along = list(cvar = c(\"tasmin\", \"tasmax\"))) #> stars object with 4 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>                                     Min.  1st Qu.   Median    Mean  3rd Qu.     Max.  NA's #> tasmin_day_HadGEM2-ES_rcp45...  266.4809 280.8343 285.1293 284.897 289.0701 302.3545 58748 #> dimension(s): #>      from   to     offset   delta refsys point         values x/y #> x       1   20     -121.2  0.0625 WGS 84 FALSE           NULL [x] #> y       1   16      37.69 -0.0625 WGS 84 FALSE           NULL [y] #> date    1 7670 2045-01-01  1 days   Date    NA           NULL     #> cvar    1    2         NA      NA     NA    NA tasmin, tasmax ## Get the names of the climate variables in these two stars objects from the index tibble (cvars_these_two <- mercd_stars_tbl %>%    slice(lst_idx) %>%    pull(cvar)) #> [1] \"tasmin\" \"tasmax\"  ## Combine the two stars objects into one (tasmin_tasmax_combined <- do.call(c, c(one_gcm_scen_lst,                                     list(along = list(cvar = cvars_these_two)))) %>%   setNames(\"val\")) #> stars object with 4 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>          Min.  1st Qu.   Median    Mean  3rd Qu.     Max.  NA's #> val  266.4809 280.8343 285.1293 284.897 289.0701 302.3545 58748 #> dimension(s): #>      from   to     offset   delta refsys point         values x/y #> x       1   20     -121.2  0.0625 WGS 84 FALSE           NULL [x] #> y       1   16      37.69 -0.0625 WGS 84 FALSE           NULL [y] #> date    1 7670 2045-01-01  1 days   Date    NA           NULL     #> cvar    1    2         NA      NA     NA    NA tasmin, tasmax"},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"date-filter","dir":"Articles","previous_headings":"Time Filters","what":"Date Filter","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"filter date, can write filter expression references ‘date’ dimension. following return just days March 15 April 14, 2050 (can verify looking range date dimension).","code":"tasmin_tasmax_combined %>% filter(date >= as.Date(\"2050-03-15\"), date <= as.Date(\"2050-04-14\")) #> stars object with 4 dimensions and 1 attribute #> attribute(s): #>          Min. 1st Qu.   Median    Mean  3rd Qu.     Max.  NA's #> val  270.9343 278.897 284.9836 287.165 295.5038 303.8904 11656 #> dimension(s): #>      from to     offset   delta refsys point         values x/y #> x       1 20     -121.2  0.0625 WGS 84 FALSE           NULL [x] #> y       1 16      37.69 -0.0625 WGS 84 FALSE           NULL [y] #> date    1 31 2050-03-15  1 days   Date    NA           NULL     #> cvar    1  2         NA      NA     NA    NA tasmin, tasmax"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"month-filter","dir":"Articles","previous_headings":"Time Filters","what":"Month Filter","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"similar fashion, can use lubridate::month() just get days March: Note result includes actual date values dimension fields (critical actually ’re regularly spaced). can visually verify got March values looking random sample date values. st_get_dimension_values() return values dimension:","code":"(tasmin_tasmax_march <- tasmin_tasmax_combined %>% filter(month(date) == 3)) #> stars object with 4 dimensions and 1 attribute #> attribute(s): #>          Min.  1st Qu.   Median     Mean  3rd Qu.     Max.   NA's #> val  267.8101 280.1277 286.4186 287.2461 294.2314 308.7601 244776 #> dimension(s): #>      from  to offset   delta refsys point                    values x/y #> x       1  20 -121.2  0.0625 WGS 84 FALSE                      NULL [x] #> y       1  16  37.69 -0.0625 WGS 84 FALSE                      NULL [y] #> date    1 651     NA      NA   Date    NA 2045-03-01,...,2065-03-31     #> cvar    1   2     NA      NA     NA    NA            tasmin, tasmax st_get_dimension_values(tasmin_tasmax_march, which = \"date\") %>% sample(20) #>  [1] \"2047-03-28\" \"2062-03-20\" \"2058-03-27\" \"2052-03-31\" \"2045-03-21\" \"2059-03-05\" \"2046-03-13\" \"2061-03-16\" \"2061-03-22\" \"2063-03-20\" #> [11] \"2056-03-30\" \"2055-03-13\" \"2057-03-22\" \"2063-03-22\" \"2063-03-01\" \"2050-03-10\" \"2052-03-04\" \"2049-03-24\" \"2046-03-28\" \"2065-03-08\""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"julian-day-filter","dir":"Articles","previous_headings":"Time Filters","what":"Julian Day Filter","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"can also filter day---year (Julian day). First get Julian day start end dates using lubridate::yday(): Filter daily temperature stars object using Julian dates: verify, let’s look first values date dimension:","code":"(jday_start <- yday(as.Date(\"2021-04-15\"))) #> [1] 105 (jday_end <- yday(as.Date(\"2021-10-01\"))) #> [1] 274 (tasmin_tasmax_ag_season <-  tasmin_tasmax_combined %>%     filter(yday(date) >= jday_start, yday(date) <= jday_end)) #> stars object with 4 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>          Min.  1st Qu.   Median     Mean 3rd Qu.     Max.  NA's #> val  274.1193 285.6643 288.6104 288.2912  291.05 302.3545 58748 #> dimension(s): #>      from   to offset   delta refsys point                    values x/y #> x       1   20 -121.2  0.0625 WGS 84 FALSE                      NULL [x] #> y       1   16  37.69 -0.0625 WGS 84 FALSE                      NULL [y] #> date    1 3570     NA      NA   Date    NA 2045-04-15,...,2065-10-01     #> cvar    1    2     NA      NA     NA    NA            tasmin, tasmax tasmin_tasmax_ag_season %>% st_get_dimension_values(\"date\") %>% head() #> [1] \"2045-04-15\" \"2045-04-16\" \"2045-04-17\" \"2045-04-18\" \"2045-04-19\" \"2045-04-20\""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"compute-gdd","dir":"Articles","previous_headings":"","what":"Compute GDD","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"Bringing together, ’ll next compute growing degree days (GDD) one season, one GCM, one emission scenario. Accumulated GDD commonly used agriculture predict tree crops ready harvest (amongst things). many flavors GDD ’ll use basic formula: GDD=(tasmin+tasmax/2)−basetempGDD = (tasmin + tasmax / 2) - basetemp basetemp crop-specific (’ll use 7 degree Celsius base temperature Pistachios).","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"prepare-one-season-of-daily-minmax-in-celsius","dir":"Articles","previous_headings":"Compute GDD","what":"Prepare one season of daily min/max in Celsius","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"First, let’s filter tasmin_tasmax_combined one growing season starting mid-April (roughly Pistachio bloom occurs): need convert values Kelvin Celsius, can making copy subtracting 273 first array:","code":"season_start <- as.Date(\"2050-04-15\") season_end <- as.Date(\"2050-09-30\")  (one_season_kelvin <- tasmin_tasmax_combined %>%   filter(date >= season_start, date <= season_end)) #> stars object with 4 dimensions and 1 attribute #> attribute(s): #>          Min. 1st Qu.   Median     Mean  3rd Qu.     Max.  NA's #> val  274.7148 288.101 295.9296 297.4148 307.0851 317.9881 63544 #> dimension(s): #>      from  to     offset   delta refsys point         values x/y #> x       1  20     -121.2  0.0625 WGS 84 FALSE           NULL [x] #> y       1  16      37.69 -0.0625 WGS 84 FALSE           NULL [y] #> date    1 169 2050-04-15  1 days   Date    NA           NULL     #> cvar    1   2         NA      NA     NA    NA tasmin, tasmax one_season_c <- one_season_kelvin one_season_c[[1]] <- one_season_c[[1]] - 273.15 one_season_c #> stars object with 4 dimensions and 1 attribute #> attribute(s): #>          Min.  1st Qu.   Median     Mean  3rd Qu.    Max.  NA's #> val  1.564752 14.95095 22.77963 24.26485 33.93511 44.8381 63544 #> dimension(s): #>      from  to     offset   delta refsys point         values x/y #> x       1  20     -121.2  0.0625 WGS 84 FALSE           NULL [x] #> y       1  16      37.69 -0.0625 WGS 84 FALSE           NULL [y] #> date    1 169 2050-04-15  1 days   Date    NA           NULL     #> cvar    1   2         NA      NA     NA    NA tasmin, tasmax"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"compute-daily-gdd","dir":"Articles","previous_headings":"Compute GDD","what":"Compute Daily GDD","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"Now can compute GDD. start writing function takes argument x, numeric vector length 2 containing min max temp day, plus basetemp. Caveat: simple GDD function doesn’t check negative GDD. Negative GDD values generally changed 0 plant insect growth generally go backwards. call custom function st_apply(). function called element dimensions loop given MARGIN. , ’re looping x, y, date. leaves cvar, dimension range two. means GDD function receive numeric vector length two (min max temp). character value passed .fname become name new attribute. TIP: alternative way writing GDD function make separate arguments tasmin tasmax. can lot faster (4x fast case). Separating arguments viable case know exactly two values passed function. passing big array values wouldn’t possible. aggregation function expects input array elements separate arguments, also add single_arg = FALSE st_apply(). Example:","code":"gdd_daily <- function(x, basetemp) {((x[1] + x[2]) / 2) - basetemp} (one_season_gdd_dly <- one_season_c %>%   st_apply(MARGIN = c(\"x\", \"y\", \"date\"), FUN = gdd_daily, basetemp = 7, .fname = \"gdd_dly\")) #> stars object with 3 dimensions and 1 attribute #> attribute(s): #>              Min. 1st Qu.   Median     Mean  3rd Qu.     Max.  NA's #> gdd_dly  4.349542 14.2549 17.41654 17.26485 20.50904 27.19601 31772 #> dimension(s): #>      from  to     offset   delta refsys point x/y #> x       1  20     -121.2  0.0625 WGS 84 FALSE [x] #> y       1  16      37.69 -0.0625 WGS 84 FALSE [y] #> date    1 169 2050-04-15  1 days   Date    NA gdd_daily_2args <- function(x1, x2, basetemp) {((x1 + x2) / 2) - basetemp}  (one_season_c %>% st_apply(MARGIN = c(\"x\", \"y\", \"date\"),                            FUN = gdd_daily_2args, basetemp = 7,                            .fname = \"gdd\", single_arg = FALSE)) #> stars object with 3 dimensions and 1 attribute #> attribute(s): #>          Min. 1st Qu.   Median     Mean  3rd Qu.     Max.  NA's #> gdd  4.349542 14.2549 17.41654 17.26485 20.50904 27.19601 31772 #> dimension(s): #>      from  to     offset   delta refsys point x/y #> x       1  20     -121.2  0.0625 WGS 84 FALSE [x] #> y       1  16      37.69 -0.0625 WGS 84 FALSE [y] #> date    1 169 2050-04-15  1 days   Date    NA"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"explore-results","dir":"Articles","previous_headings":"Compute GDD","what":"Explore results","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"Let’s drill get GDD values point center county: Get values location using st_extract(): Look closely results. st_extract() returned array first dimension represents x values (.e., columns raster), vector features (case points). Dimension two (usually reserved ‘y’) now represents dates, values elements represent daily GDD. 3rd dimension. Hence pull array [[ ]] expect two-dimensional array rows represent features, columns represent days, values represent GDD: Using knowledge results st_extract() structured, can make scatter plot daily GDD time:","code":"(mercd_ctr_sf <- st_centroid(mercd_bnd_sf)) #> Geometry set for 1 feature  #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -120.7186 ymin: 37.19131 xmax: -120.7186 ymax: 37.19131 #> Geodetic CRS:  WGS 84 #> POINT (-120.7186 37.19131) (gdd_ctr_stars <- one_season_gdd_dly %>% st_extract(mercd_ctr_sf)) #> stars object with 2 dimensions and 1 attribute #> attribute(s): #>              Min.  1st Qu.   Median     Mean  3rd Qu.     Max. #> gdd_dly  9.925531 15.15791 18.35623 18.03055 20.98876 26.69079 #> dimension(s): #>          from  to     offset  delta refsys point               values #> geometry    1   1         NA     NA WGS 84  TRUE POINT (-120.7 37.19) #> date        1 169 2050-04-15 1 days   Date    NA                 NULL dim(gdd_ctr_stars[[1]]) #>      date  #>    1  169 summary(gdd_ctr_stars[[1]][1,]) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   9.926  15.158  18.356  18.031  20.989  26.691 gdd_ctr_dates <- gdd_ctr_stars %>% st_get_dimension_values(\"date\") str(gdd_ctr_dates) #>  Date[1:169], format: \"2050-04-15\" \"2050-04-16\" \"2050-04-17\" \"2050-04-18\" \"2050-04-19\" \"2050-04-20\" \"2050-04-21\" \"2050-04-22\" \"2050-04-23\" \"2050-04-24\" ...  ggplot(data.frame(date = gdd_ctr_dates, daily_gdd = gdd_ctr_stars[[1]][1,]),        aes(x = date, y = daily_gdd)) +   geom_line() +   labs(title = \"Projected Daily GDD at the Centroid of Merced County, 2050\",        caption = \"Simple average method. Base temp: 7 C. GCM: HadGEM2-ES. Scenario: RCP45.\")"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"accumulated-gdd","dir":"Articles","previous_headings":"Compute GDD","what":"Accumulated GDD","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"Next, compute accumulated GDD looping x y, passing remaining dimensions (case 169 values daily GDD) cumsum(). pixel, ’ll get back 169 values placed new dimension ’ll call ‘date’. ’re can also set name attribute (values) ‘gdd_csum’. worked lost properties new dimension returned st_apply(). know new dimension still represents original dates, can copy ‘date’ dimension one_season_gdd_dly: verify, can get values one pixel plot :  looks right!","code":"one_season_gdd_csum <- one_season_gdd_dly %>%   st_apply(c(\"x\", \"y\"), cumsum, .fname = \"date\") %>%   setNames(\"gdd_csum\")  one_season_gdd_csum #> stars object with 3 dimensions and 1 attribute #> attribute(s): #>               Min. 1st Qu.   Median    Mean  3rd Qu.     Max.  NA's #> gdd_csum  6.511469 548.138 1285.735 1365.29 2152.067 3102.194 31772 #> dimension(s): #>      from  to offset   delta refsys point x/y #> date    1 169     NA      NA     NA    NA     #> x       1  20 -121.2  0.0625 WGS 84 FALSE [x] #> y       1  16  37.69 -0.0625 WGS 84 FALSE [y] st_dimensions(one_season_gdd_csum)$date <- st_dimensions(one_season_gdd_dly)$date one_season_gdd_csum #> stars object with 3 dimensions and 1 attribute #> attribute(s): #>               Min. 1st Qu.   Median    Mean  3rd Qu.     Max.  NA's #> gdd_csum  6.511469 548.138 1285.735 1365.29 2152.067 3102.194 31772 #> dimension(s): #>      from  to     offset   delta refsys point x/y #> date    1 169 2050-04-15  1 days   Date    NA     #> x       1  20     -121.2  0.0625 WGS 84 FALSE [x] #> y       1  16      37.69 -0.0625 WGS 84 FALSE [y] one_pt_gddcsum <- one_season_gdd_csum %>%   slice(10, along = \"x\") %>%   slice(8, along = \"y\") %>%   pull(gdd_csum)  ggplot(data.frame(dt = one_season_gdd_csum %>% st_get_dimension_values(\"date\"),                   gdd_csum = one_pt_gddcsum),        aes(x = dt, y = gdd_csum)) +   geom_line()"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"plot-a-accumulated-gdd-surface","dir":"Articles","previous_headings":"Compute GDD","what":"Plot a Accumulated GDD Surface","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"Plot GDD looks like July 15, 2050:","code":"plot(one_season_gdd_csum %>%        filter(date == as.Date(\"2050-07-15\")),      main = \"Projected Accumulated GDD July 15, 2050\",      reset = FALSE) ## Add some details about the data text(-121.2600, 37.61369, \"GDD start: April 15, 2050\\nGCM: HadGEM2-ES\\nScenario: RCP45\\nBasetemp: 7 C\", adj = c(0,1))"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"save-to-disk","dir":"Articles","previous_headings":"","what":"Save to disk","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"can save stars objects TIF files write_stars(): Note however TIF files limited 3-dimensional rasters (x, y, layers), general can’t save properties layers, date value (precisely ca_getrst_stars() writes sidecar files downloading TIFs). alternative saving stars objects TIFs save regular R object using save() saveRDS(). record stars object completely, limitation formats useful bring objects back R. also simply save code recreate stars objects fly re-importing TIF files downloaded Cal-Adapt. netCDF much better file format multidimensional spatiotemporal arrays. stars package equipped directly save stars objects netCDF (help may way).","code":"tif_fn <- file.path(tempdir(), \"merced_2050_cum-gdd-base7.tif\") # write_stars(one_season_gdd_csum, dsn = tif_fn)"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt1.html","id":"how-many-frost-days-per-year","dir":"Articles","previous_headings":"","what":"How many frost days per year?","title":"Rasters Part I: Download, Combine, Subset, and Compute Pixel Summaries","text":"Next, let’s count number frost days, ’ll approximate day minimum temperature <= 0 °C (robust way measure frost exposure, see Parker et al 2020). task doesn’t require anything fancy stars. already projected minimum daily temperature every pixel Merced County 20 years. just check 0. However ’ll get little creative extracting information stars object, wind summary number frozen pixels per year. First make copy first stars object (records tasmin) list: Identifying pixels fall freezing easy part. following take minimum daily temperature arrays TRUE temperature 273 (equivalent 0 °C), otherwise FALSE: Finding total number pixels-days freezing also pretty easy. simply grab TRUE/FALSE values pull(1) ([[1]]), sum . add TRUE/FALSE values, TRUEs become 1 FALSEs become 0. can feed table(): doesn’t really answer question. want look number frozen pixels per year, grand total 20 years. generate yearly summary need expression four things: loops years pulls daily rasters specific year sums number frozen pixels stores results data frame First get years: Now can write little loop builds data frame number frozen pixels per year: compact way :","code":"(tmin_allyrs_stars <- mercd_stars_lst[[1]]) #> stars object with 3 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>                                     Min.  1st Qu.   Median    Mean  3rd Qu.     Max.  NA's #> tasmin_day_HadGEM2-ES_rcp45...  266.4809 280.8343 285.1293 284.897 289.0701 302.3545 58748 #> dimension(s): #>      from   to     offset   delta refsys point x/y #> x       1   20     -121.2  0.0625 WGS 84 FALSE [x] #> y       1   16      37.69 -0.0625 WGS 84 FALSE [y] #> date    1 7670 2045-01-01  1 days   Date    NA (frost_allyrs_stars <- tmin_allyrs_stars <= 273) #> stars object with 3 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>  tasmin_day_HadGEM2-ES_rcp45...  #>  Mode :logical                   #>  FALSE:40233                     #>  TRUE :1019                      #>  NA's :58748                     #> dimension(s): #>      from   to     offset   delta refsys point x/y #> x       1   20     -121.2  0.0625 WGS 84 FALSE [x] #> y       1   16      37.69 -0.0625 WGS 84 FALSE [y] #> date    1 7670 2045-01-01  1 days   Date    NA frost_allyrs_stars %>% pull() %>% table() #> . #>  FALSE   TRUE  #> 985914  26526 (tmin_allyrs_stars %>% st_get_dimension_values(\"date\") %>% year() %>% unique() -> years_all) #>  [1] 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 year_numfrost_df <- NULL for (yr in years_all) {   year_numfrost_df <- year_numfrost_df %>%     rbind(data.frame(year = yr,                      num_frozen_pixels = frost_allyrs_stars %>% filter(year(date) == yr) %>%                        pull() %>% sum(na.rm = TRUE))) } year_numfrost_df #>    year num_frozen_pixels #> 1  2045              1345 #> 2  2046               749 #> 3  2047              2134 #> 4  2048              3286 #> 5  2049               592 #> 6  2050               453 #> 7  2051              1291 #> 8  2052               538 #> 9  2053              1491 #> 10 2054              1966 #> 11 2055              2037 #> 12 2056              1424 #> 13 2057              1132 #> 14 2058              1473 #> 15 2059              1021 #> 16 2060              2121 #> 17 2061              1335 #> 18 2062               314 #> 19 2063               889 #> 20 2064               380 #> 21 2065               555 do.call(rbind, lapply(years_all, function(yr)   data.frame(year = yr,              frost_pixel_days = frost_allyrs_stars %>% filter(year(date) == yr) %>%                pull() %>% sum(na.rm = TRUE)) )) #>    year frost_pixel_days #> 1  2045             1345 #> 2  2046              749 #> 3  2047             2134 #> 4  2048             3286 #> 5  2049              592 #> 6  2050              453 #> 7  2051             1291 #> 8  2052              538 #> 9  2053             1491 #> 10 2054             1966 #> 11 2055             2037 #> 12 2056             1424 #> 13 2057             1132 #> 14 2058             1473 #> 15 2059             1021 #> 16 2060             2121 #> 17 2061             1335 #> 18 2062              314 #> 19 2063              889 #> 20 2064              380 #> 21 2065              555"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt2.html","id":"think-of-rasters-as-arrays","dir":"Articles","previous_headings":"","what":"Think of rasters as arrays","title":"Rasters Part II: Six-Dimensional Climate Data Cubes and Spatial Queries","text":"term ‘raster’ pretty familiar intuitive anyone little experience remote sensing even photography. However work effectively efficiently raster data Cal-Adapt using powerful functions stars package, ’ll get mileage think data terms arrays. Like rasters, arrays structures organizing data multiple dimensions, including regular grids layers (.e., bands). Rasters kind array, arrays general extensible rasters. example arrays can 3 dimensions. convert Cal-Adapt raster data six dimensional arrays, dimensions include x, y, date, gcm, scenario, climate variable. might ask - anyone want work 6-dimensional array, instead intuitive raster format layers represent slices time? single 3D raster deal , yes standard raster methods functions probably suffice. However ’re dealing data climate models, ’re probably going work many rasters, representing different emission scenarios, GCMs, climate variables. Quite likely analysis also apply analysis several rasters, combine compare results. Rasters Part vignette, saw work programmatically individual stars objects saved list, assistance list ‘index’ created ca_stars_index(). approach can klunky. combining rasters high dimensional array, can write code lot concise, consistent, (eventually) intuitive. vignette, ’ll see combine 3D stars objects downloaded Cal-Adapt single six-dimensional stars object, climate data cube, slice dice data using square bracket notation dplyr verbs analysis.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt2.html","id":"import-merced-county-raster-data","dir":"Articles","previous_headings":"","what":"Import Merced County raster data","title":"Rasters Part II: Six-Dimensional Climate Data Cubes and Spatial Queries","text":"Start loading packages ’ll use: Next, import TIF files downloaded Rasters Part . Import TIF files list stars objects:","code":"library(caladaptr) library(dplyr) library(sf) library(stars) library(magrittr) library(tmap) library(lubridate) data_dir <- tools::R_user_dir(\"caladaptr\", which = \"data\") merced_dir <- file.path(data_dir, \"merced\") merced_tifs_fn <- list.files(merced_dir, pattern = \".tif$\", full.names = TRUE) basename(merced_tifs_fn) #>  [1] \"tasmax_day_CanESM2_rcp45_fips-06047.tif\"    \"tasmax_day_CanESM2_rcp85_fips-06047.tif\"    \"tasmax_day_CNRM-CM5_rcp45_fips-06047.tif\"   #>  [4] \"tasmax_day_CNRM-CM5_rcp85_fips-06047.tif\"   \"tasmax_day_HadGEM2-ES_rcp45_fips-06047.tif\" \"tasmax_day_HadGEM2-ES_rcp85_fips-06047.tif\" #>  [7] \"tasmax_day_MIROC5_rcp45_fips-06047.tif\"     \"tasmax_day_MIROC5_rcp85_fips-06047.tif\"     \"tasmin_day_CanESM2_rcp45_fips-06047.tif\"    #> [10] \"tasmin_day_CanESM2_rcp85_fips-06047.tif\"    \"tasmin_day_CNRM-CM5_rcp45_fips-06047.tif\"   \"tasmin_day_CNRM-CM5_rcp85_fips-06047.tif\"   #> [13] \"tasmin_day_HadGEM2-ES_rcp45_fips-06047.tif\" \"tasmin_day_HadGEM2-ES_rcp85_fips-06047.tif\" \"tasmin_day_MIROC5_rcp45_fips-06047.tif\"     #> [16] \"tasmin_day_MIROC5_rcp85_fips-06047.tif\" mercd_stars_lst <- ca_stars_read(merced_tifs_fn) names(mercd_stars_lst) #>  [1] \"tasmax_day_CanESM2_rcp45_fips-06047\"    \"tasmax_day_CanESM2_rcp85_fips-06047\"    \"tasmax_day_CNRM-CM5_rcp45_fips-06047\"   #>  [4] \"tasmax_day_CNRM-CM5_rcp85_fips-06047\"   \"tasmax_day_HadGEM2-ES_rcp45_fips-06047\" \"tasmax_day_HadGEM2-ES_rcp85_fips-06047\" #>  [7] \"tasmax_day_MIROC5_rcp45_fips-06047\"     \"tasmax_day_MIROC5_rcp85_fips-06047\"     \"tasmin_day_CanESM2_rcp45_fips-06047\"    #> [10] \"tasmin_day_CanESM2_rcp85_fips-06047\"    \"tasmin_day_CNRM-CM5_rcp45_fips-06047\"   \"tasmin_day_CNRM-CM5_rcp85_fips-06047\"   #> [13] \"tasmin_day_HadGEM2-ES_rcp45_fips-06047\" \"tasmin_day_HadGEM2-ES_rcp85_fips-06047\" \"tasmin_day_MIROC5_rcp45_fips-06047\"     #> [16] \"tasmin_day_MIROC5_rcp85_fips-06047\""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt2.html","id":"create-a-6d-data-cube","dir":"Articles","previous_headings":"","what":"Create a 6D data cube","title":"Rasters Part II: Six-Dimensional Climate Data Cubes and Spatial Queries","text":"ca_stars_6d() takes list 3D stars objects returns 6D stars object. new dimensions generated Cal-Adapt metadata first saved sidecar files downloaded TIF files, imported along TIFs ran ca_stars_read(). two important requirements combining multiple 3D stars objects one 6D stars object: stars objects (TIFs) must cover spatial area. climate variables individual stars objects must use units. example can combine tasmin tasmax 6D raster, units degrees Kelvin. can’t combine temperature precipitation. Turn list 3D stars objects 6 stars object: Note addition dimensions scenario, gcm, cvar. example, dimensions 2 values, even one value list stars objects still included stars object returned ca_stars_6d(). extra dimensions can used subset stars object. example just wanted climate variables emissions scenario rcp85, GCM MIROC5, Jan-March, write expression filter():","code":"(mercd_stars_6d <- ca_stars_6d(mercd_stars_lst)) #> stars object with 6 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>          Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  NA's #> val  276.0979 285.4992 287.7837 287.9336 290.1285 299.0094 58748 #> dimension(s): #>          from   to     offset   delta refsys point             values x/y #> x           1   20     -121.2  0.0625 WGS 84 FALSE               NULL [x] #> y           1   16      37.69 -0.0625 WGS 84 FALSE               NULL [y] #> scenario    1    2         NA      NA     NA    NA       rcp45, rcp85     #> gcm         1    4         NA      NA     NA    NA CanESM2,...,MIROC5     #> date        1 7670 2045-01-01  1 days   Date    NA               NULL     #> cvar        1    2         NA      NA     NA    NA     tasmax, tasmin (mercd_stars_6d %>%   filter(scenario == \"rcp85\", gcm == \"MIROC5\", month(date) <= 3)) #> stars object with 6 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>          Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  NA's #> val  278.0172 286.6794 289.8948 290.3535 293.5023 303.4041 58748 #> dimension(s): #>          from   to offset   delta refsys point                    values x/y #> x           1   20 -121.2  0.0625 WGS 84 FALSE                      NULL [x] #> y           1   16  37.69 -0.0625 WGS 84 FALSE                      NULL [y] #> scenario    1    1     NA      NA     NA    NA                     rcp85     #> gcm         1    1     NA      NA     NA    NA                    MIROC5     #> date        1 1895     NA      NA   Date    NA 2045-01-01,...,2065-03-31     #> cvar        1    2     NA      NA     NA    NA            tasmax, tasmin"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt2.html","id":"subsetting-with-square-brackets","dir":"Articles","previous_headings":"","what":"Subsetting with square brackets","title":"Rasters Part II: Six-Dimensional Climate Data Cubes and Spatial Queries","text":"alternative way subsetting stars object square brackets, similar can subset matrices arrays base R. template subsetting 6D array looks like: my_6d_stars_object[spatial object attribute, x-indices, y-indices, scenario indices, gcm indices, date indices, cvar-indices] TIP: Square bracket notation way can subset rasters single row single column. Square bracket notation common matrices data frames base R, couple key differences subsetting stars object traditional matrix. first slot allows pass spatial object, used perform spatial query, name attribute. Hence one extra comma square brackets. context attribute refers attributes stars object (.e., names array values), vector feature. 6D stars object one attribute, val, stars object capable multiple attributes element array. expressions dimensions can accept indices, logical values dimension values. Expressions like cvar == 'MIROC5', work fine subset regular matrix, won’t work stars object. Logical expressions can course easily converted indices using (). Similar traditional subsetting, omit expression values dimension returned. Commas omitted, unless expressions follow.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt2.html","id":"example-1--square-bracket-notation-to-subet-multiple-dimensions-simultaneously","dir":"Articles","previous_headings":"Subsetting with square brackets","what":"Example 1. Square bracket notation to subet multiple dimensions simultaneously","title":"Rasters Part II: Six-Dimensional Climate Data Cubes and Spatial Queries","text":"following examples demonstrate subset square brackets get subset consisting : emissions scenario: rcp85 GCM: CNRM-CM5 MIROC5 date: winter monthly (December thru March)","code":"(scen_idx <- mercd_stars_6d %>%   st_get_dimension_values(\"scenario\") %>%   equals(\"rcp45\") %>%   which()) #> [1] 1  (gcm_idx <- mercd_stars_6d %>%   st_get_dimension_values(\"gcm\") %>%   is_in( c(\"CNRM-CM5\", \"MIROC5\")) %>%   which()) #> [1] 2 4  date_idx <- mercd_stars_6d %>%   st_get_dimension_values(\"date\") %>%   month() %>%   is_in( c(12, 1, 2, 3)) %>%   which() str(date_idx) #>  int [1:2546] 1 2 3 4 5 6 7 8 9 10 ...  mercd_stars_6d[ , , , scen_idx, gcm_idx, date_idx, ] #> stars object with 6 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>          Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  NA's #> val  279.2779 285.8354 288.1668 288.8418 291.2101 304.4528 58748 #> dimension(s): #>          from   to offset   delta refsys point                                              values x/y #> x           1   20 -121.2  0.0625 WGS 84 FALSE                                                NULL [x] #> y           1   16  37.69 -0.0625 WGS 84 FALSE                                                NULL [y] #> scenario    1    1     NA      NA     NA    NA                                               rcp45     #> gcm         1    2     NA      NA     NA    NA                                  CNRM-CM5, MIROC5       #> date        1 2546     NA      NA   Date    NA [2045-01-01,2045-01-02),...,[2065-12-31,2066-01-01)     #> cvar        1    2     NA      NA     NA    NA                                      tasmax, tasmin"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt2.html","id":"example-2--square-bracket-notation-within-a-loop","dir":"Articles","previous_headings":"Subsetting with square brackets","what":"Example 2. Square bracket notation within a loop","title":"Rasters Part II: Six-Dimensional Climate Data Cubes and Spatial Queries","text":"wanted aggregate pixel values across time using function accumulated GDD, combinations emissions scenario GCM, use square bracket notation within loop. following example, double loop set loop scenarios followed GCMs. Cumulative GDD computed saved list.","code":"## Get the names for the scenarios and GCM. We will loop through these. (scen_names <- mercd_stars_6d %>% st_get_dimension_values(\"scenario\")) #> [1] \"rcp45\" \"rcp85\" (gcm_names <- mercd_stars_6d %>% st_get_dimension_values(\"gcm\")) #> [1] \"CanESM2\"    \"CNRM-CM5\"   \"HadGEM2-ES\" \"MIROC5\"  ## Select a range of dates in 2050. If we wanted all years this could also go into a loop. date_idx <- mercd_stars_6d %>%   st_get_dimension_values(\"date\") %>%   year() %>%   `==`(2050) %>%   which()  ## Create a pixel aggregation function that computes the accumulated GDD. ## The argument x will be a 2-column matrix where the rows are dates and ## and the columns are cvars (tasmax and tasmin) gdd_csum <- function(x, basetemp) {  cumsum( (apply(x - 273, MARGIN = 1, sum) / 2) - basetemp) }  ## Create a blank list to hold the results gdd_stars_lst <- list()  for (sc_idx in 1:length(scen_names)) {    ## Create a first level list for this scenario   gdd_stars_lst[[scen_names[sc_idx]]] <- list()    for (gcm_idx in 1:length(gcm_names)) {      ## Add the stars element to the first level list     gdd_stars_lst[[scen_names[sc_idx]]][[gcm_names[gcm_idx]]] <-       mercd_stars_6d[ , , , sc_idx, gcm_idx, date_idx, ] %>%       st_apply(MARGIN = c(\"x\", \"y\", \"scenario\", \"gcm\"),                            FUN = gdd_csum, basetemp = 7,                            .fname = \"my_gdd_csum\", single_arg = TRUE) %>%       setNames(\"gdd_csum\")   } }  sapply(gdd_stars_lst, names) #>      rcp45        rcp85        #> [1,] \"CanESM2\"    \"CanESM2\"    #> [2,] \"CNRM-CM5\"   \"CNRM-CM5\"   #> [3,] \"HadGEM2-ES\" \"HadGEM2-ES\" #> [4,] \"MIROC5\"     \"MIROC5\""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt2.html","id":"spatial-subsetting","dir":"Articles","previous_headings":"","what":"Spatial Subsetting","title":"Rasters Part II: Six-Dimensional Climate Data Cubes and Spatial Queries","text":"can spatially subset stars object passing sf object first slot square brackets, using st_crop(). two methods equivalent. sf object must CRS stars object. example suppose interested Black Rascal Creek HUC10 watershed, lies Merced County:  subset 6D stars object square bracket notation, simply put sf object first slot:  TIP: pass sf object slot 1 square brakets, rest slots ignored remaining commas can omitted. Hence can’t spatially subset stars object simultaneously subsetting along dimension(s). Spatial subsetting dimension subsetting need separate expressions.  ’s spatial subsetting looks like st_crop(): crop = TRUE (default) tells reduce extent cropped object. Alternately keep original number rows columns set outside cropped NA. verify can plot subset area (additional filters just get one layer) overlaid watershed boundary:  plot reflects intersection rule st_crop() applies pixels along edges polygon. order pixel counted part intersection, center needs within polygon boundary. wanted err side inclusion, crop using extent watershed boundary:","code":"mercd_bnd_sf <- ca_aoipreset_geom(\"counties\") %>%   filter(fips == \"06047\") %>%   select(name, state_name, fips) %>%   st_transform(4326) #> Reading layer `counties' from data source `C:\\Users\\Andy\\AppData\\Local\\R\\cache\\R\\caladaptr\\counties.gpkg' using driver `GPKG' #> Simple feature collection with 87 features and 54 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: -13871160 ymin: 3833648 xmax: -12625080 ymax: 5416187 #> Projected CRS: WGS 84 / Pseudo-Mercator  black_rascal_creek_sf <- ca_aoipreset_geom(\"hydrounits\") %>%   filter(huc10 == \"1804000114\") %>%   st_transform(4326) #> Reading layer `hydrounits' from data source `C:\\Users\\Andy\\AppData\\Local\\R\\cache\\R\\caladaptr\\hydrounits.gpkg' using driver `GPKG' #> Simple feature collection with 958 features and 15 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: -13863190 ymin: 3808721 xmax: -12735560 ymax: 5186222 #> Projected CRS: WGS 84 / Pseudo-Mercator  tm_shape(mercd_bnd_sf) +   tm_borders(col = \"red\") +   tm_shape(black_rascal_creek_sf) +   tm_borders() (mercd_stars_6d[black_rascal_creek_sf, , , , , , ]) #> stars object with 6 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>          Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  NA's #> val  278.0972 292.3456 300.7236 300.3874 308.6533 318.9679 41668 #> dimension(s): #>          from   to     offset   delta refsys point             values x/y #> x          12   15     -121.2  0.0625 WGS 84 FALSE               NULL [x] #> y           4    6      37.69 -0.0625 WGS 84 FALSE               NULL [y] #> scenario    1    2         NA      NA     NA    NA       rcp45, rcp85     #> gcm         1    4         NA      NA     NA    NA CanESM2,...,MIROC5     #> date        1 7670 2045-01-01  1 days   Date    NA               NULL     #> cvar        1    2         NA      NA     NA    NA     tasmax, tasmin (brc_stars_6d <- mercd_stars_6d %>% st_crop(black_rascal_creek_sf, crop = TRUE)) #> stars object with 6 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>          Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  NA's #> val  278.0972 292.3456 300.7236 300.3874 308.6533 318.9679 41668 #> dimension(s): #>          from   to     offset   delta refsys point             values x/y #> x          12   15     -121.2  0.0625 WGS 84 FALSE               NULL [x] #> y           4    6      37.69 -0.0625 WGS 84 FALSE               NULL [y] #> scenario    1    2         NA      NA     NA    NA       rcp45, rcp85     #> gcm         1    4         NA      NA     NA    NA CanESM2,...,MIROC5     #> date        1 7670 2045-01-01  1 days   Date    NA               NULL     #> cvar        1    2         NA      NA     NA    NA     tasmax, tasmin plot(brc_stars_6d %>% filter(scenario == \"rcp45\", gcm == \"MIROC5\",                              date == as.Date(\"2050-01-01\"), cvar == \"tasmin\"),      axes = TRUE, reset = FALSE) plot(black_rascal_creek_sf %>% st_geometry(), border = \"red\", lwd = 2, add = TRUE) (brc_bb_stars_6d <- mercd_stars_6d %>%    st_crop(black_rascal_creek_sf %>% st_bbox() %>% st_as_sfc(), crop = TRUE)) #> stars object with 6 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>          Min.  1st Qu.   Median     Mean  3rd Qu.     Max. #> val  278.0972 292.3031 300.6886 300.3325 308.5641 318.9679 #> dimension(s): #>          from   to     offset   delta refsys point             values x/y #> x          12   15     -121.2  0.0625 WGS 84 FALSE               NULL [x] #> y           4    6      37.69 -0.0625 WGS 84 FALSE               NULL [y] #> scenario    1    2         NA      NA     NA    NA       rcp45, rcp85     #> gcm         1    4         NA      NA     NA    NA CanESM2,...,MIROC5     #> date        1 7670 2045-01-01  1 days   Date    NA               NULL     #> cvar        1    2         NA      NA     NA    NA     tasmax, tasmin  plot(brc_bb_stars_6d %>% filter(scenario == \"rcp45\", gcm == \"MIROC5\",                              date == as.Date(\"2050-01-01\"), cvar == \"tasmin\"),      axes = TRUE, reset = FALSE) plot(black_rascal_creek_sf %>% st_geometry(), border = \"red\", lwd = 2, add = TRUE)"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt2.html","id":"spatial-aggregation","dir":"Articles","previous_headings":"","what":"Spatial Aggregation","title":"Rasters Part II: Six-Dimensional Climate Data Cubes and Spatial Queries","text":"Spatial aggregation combines extracting pixel values spatial features aggregation function like mean collapses values single number feature. output stars vector cube, like sf object however attribute table multidimensional array. can use aggregate() spatial aggregations stars objects. aggregate() can also used aggregate values time, can’t call. used spatial aggregation, inputs aggregate() include stars object sf object. Unlike flexible st_apply(), aggregate() can aggregate one attribute (layer) time. words, need combine time series data single metric (GDD), also aggregate results polygons, break different steps. can either aggregate time data polygon compute GDD metric, compute GDD metric pixel (using st_apply()) aggregate polygon. choice order affect results.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt2.html","id":"compute-accumulated-gdd-for-merced-county-supervisor-districts","dir":"Articles","previous_headings":"Spatial Aggregation","what":"Compute Accumulated GDD for Merced County Supervisor Districts","title":"Rasters Part II: Six-Dimensional Climate Data Cubes and Spatial Queries","text":"illustrate temporal spatial aggregation can combined, ’ll compute projected accumulated GDD Merced County Board Supervisors Districts one calendar year, one emissions scenario, one GCM. ’ll first compute daily GDD pixel, can take advantage fine scale resolution data. Next ’ll use aggregate() get mean daily GDD district. Lastly, ’ll go back st_apply() generate cumulative sum mean daily GDD district. Begin importing supervisor district boundaaries (source):  Next simplify task creating stars object daily min / max temp just one year, one emissions scenario, GCM: Next, compute daily GDD (see Rasters Part 1 vignette details): Now ’re ready use aggregate() get average daily GDD Supervisor district. averaging across polygons, daily values (.e., time dimension) still kept separate ’re going need create cumulative sum final step. now 365 daily GDD values 5 poglyons. last step create cumulative sum: Plot accumulated curves (one curve Supervisor District):  Plot accumulated GDD per Supervisor district Sept 30, 2050.","code":"mercd_bos_dist_fn <- file.path(merced_dir, \"mercd_bos_dist.geojson\") %>% normalizePath()  if (!file.exists(mercd_bos_dist_fn)) {   download.file(\"https://raw.githubusercontent.com/ucanr-igis/caladaptr-res/main/geoms/merced_bos_districts.geojson\", mercd_bos_dist_fn, quiet = TRUE) }  (mercd_bos_dist_sf <- st_read(mercd_bos_dist_fn, quiet = TRUE) %>%   select(districtid)) #> Simple feature collection with 5 features and 1 field #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: -121.2487 ymin: 36.74039 xmax: -120.0521 ymax: 37.63337 #> Geodetic CRS:  WGS 84 #>   districtid                       geometry #> 1          1 MULTIPOLYGON (((-120.5824 3... #> 2          4 MULTIPOLYGON (((-121.0675 3... #> 3          5 MULTIPOLYGON (((-120.6155 3... #> 4          2 MULTIPOLYGON (((-120.5048 3... #> 5          3 MULTIPOLYGON (((-120.5953 3...  tm_shape(mercd_bos_dist_sf) + tm_fill(col = \"districtid\") (mercd_2050_stars <- mercd_stars_6d %>%   filter(scenario == \"rcp45\", gcm == \"MIROC5\", year(date) == 2050)) #> stars object with 6 dimensions and 1 attribute #> attribute(s): #>          Min.  1st Qu.   Median    Mean  3rd Qu.     Max.   NA's #> val  268.8781 282.9231 289.3158 291.674 300.5461 320.2531 137240 #> dimension(s): #>          from  to     offset   delta refsys point         values x/y #> x           1  20     -121.2  0.0625 WGS 84 FALSE           NULL [x] #> y           1  16      37.69 -0.0625 WGS 84 FALSE           NULL [y] #> scenario    1   1         NA      NA     NA    NA          rcp45     #> gcm         1   1         NA      NA     NA    NA         MIROC5     #> date        1 365 2050-01-01  1 days   Date    NA           NULL     #> cvar        1   2         NA      NA     NA    NA tasmax, tasmin gdd_daily_2args <- function(x1, x2, basetemp) {((x1 + x2) / 2) - 273.15 - basetemp}  (mercd_2050_dlygdd_stars <- mercd_2050_stars %>%     st_apply(MARGIN = c(\"x\", \"y\", \"scenario\", \"gcm\", \"date\"),              FUN = gdd_daily_2args, basetemp = 7,              .fname = \"dly_gdd\", single_arg = FALSE)) #> stars object with 5 dimensions and 1 attribute #> attribute(s): #>               Min. 1st Qu.   Median     Mean  3rd Qu.     Max.  NA's #> dly_gdd  -6.116125  5.6051 11.43466 11.52398 17.02358 27.52923 68620 #> dimension(s): #>          from  to     offset   delta refsys point values x/y #> x           1  20     -121.2  0.0625 WGS 84 FALSE   NULL [x] #> y           1  16      37.69 -0.0625 WGS 84 FALSE   NULL [y] #> scenario    1   1         NA      NA     NA    NA  rcp45     #> gcm         1   1         NA      NA     NA    NA MIROC5     #> date        1 365 2050-01-01  1 days   Date    NA   NULL (bod_2050_dlygdd_stars <- mercd_2050_dlygdd_stars %>%   aggregate(by = mercd_bos_dist_sf, FUN = mean)) #> stars object with 4 dimensions and 1 attribute #> attribute(s): #>               Min.  1st Qu.   Median     Mean  3rd Qu.     Max. #> dly_gdd  -2.937308 5.640863 11.66823 11.71801 17.26827 26.58949 #> dimension(s): #>          from  to     offset  delta refsys point                                                        values #> geometry    1   5         NA     NA WGS 84 FALSE MULTIPOLYGON (((-120.5824...,...,MULTIPOLYGON (((-120.5953... #> scenario    1   1         NA     NA     NA    NA                                                         rcp45 #> gcm         1   1         NA     NA     NA    NA                                                        MIROC5 #> date        1 365 2050-01-01 1 days   Date    NA                                                          NULL bod_2050_csumgdd_stars <- bod_2050_dlygdd_stars %>%   st_apply(MARGIN = c(\"geometry\", \"scenario\", \"gcm\"),            FUN = cumsum, .fname = \"date\") %>%   aperm(c(2,3,4,1)) %>%   setNames(\"csum_gdd\")  ## Copy the properties of the 'date' dimension st_dimensions(bod_2050_csumgdd_stars)[\"date\"] <- st_dimensions(bod_2050_dlygdd_stars)[\"date\"]  bod_2050_csumgdd_stars #> stars object with 4 dimensions and 1 attribute #> attribute(s): #>                 Min.  1st Qu.  Median    Mean  3rd Qu.     Max. #> csum_gdd  -0.6124481 443.5684 1775.67 1990.72 3553.634 4376.372 #> dimension(s): #>          from  to     offset  delta refsys point                                                        values #> geometry    1   5         NA     NA WGS 84 FALSE MULTIPOLYGON (((-120.5824...,...,MULTIPOLYGON (((-120.5953... #> scenario    1   1         NA     NA     NA    NA                                                         rcp45 #> gcm         1   1         NA     NA     NA    NA                                                        MIROC5 #> date        1 365 2050-01-01 1 days   Date    NA                                                          NULL gdd_csum_df <- bod_2050_csumgdd_stars[, , , , drop=TRUE] %>%   pull(1) %>%   t() %>%   as.data.frame() %>%   setNames(c(\"Dist1\", \"Dist2\", \"Dist3\", \"Dist4\", \"Dist5\"))  matplot(x = 1:nrow(gdd_csum_df), y = gdd_csum_df, type=\"l\", lty = 1) plot(bod_2050_csumgdd_stars %>% filter(date == as.Date(\"2050-09-30\")),      main = \"Accumulated GDD: Jan 1 - Sept 30, 2050\")"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt3.html","id":"introdution","dir":"Articles","previous_headings":"","what":"Introdution","title":"Rasters Part III: Downloading Rasters for Large Areas","text":"Cal-Adapt API great way get rasters, can specify exactly area want, climate variable(s) want, time frame want. However raster files inherently large, ’s upper limit large area get one call. Hence need strategies download work rasters large areas (state California). vignette outlines approach downloading working rasters large areas. essence strategy 1) downloading rasters series blocks collectively cover entire area--interest, 2) mosaic individual blocks get one seamless raster. ’ll also see can combine multiple 3D mosaiced rasters single six-dimensional raster, explained Part 2, use parallel processing speed pixelwise operations. first…","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt3.html","id":"downloading-netcdf-files","dir":"Articles","previous_headings":"Introdution","what":"Downloading NetCDF Files","title":"Rasters Part III: Downloading Rasters for Large Areas","text":"alternative downloading rasters API simply download source NetCDF files Cal-Adapt Data Server. NetCDF files full extent Cal-Adapt’s LOCA downscaled data daily time scale available download FTP/HTTP. can import NetCDF files R using stars::read_stars() well packages. caladaptr provide functions support original NetCDF data.  NetCDF files full extent Cal-Adapt’s LOCA downscaled climate data available download Cal-Adapt Data Server","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt3.html","id":"break-up-a-large-area-of-interest-into-blocks","dir":"Articles","previous_headings":"","what":"Break-up a large area-of-interest into blocks","title":"Rasters Part III: Downloading Rasters for Large Areas","text":"illustrate working large areas, example ’ll download TIFs 50 years annual precipitation data several scenarios GCMs, entire state California. First load packages: begin importing state boundary:   entire state far big use API call, can break blocks 20,000 mi2 less using ca_biggeom_blocks():","code":"library(caladaptr) library(dplyr) library(sf) library(stars) library(magrittr) library(tmap) tmap_mode(\"plot\") ca_bnd_url <- \"https://raw.githubusercontent.com/ucanr-igis/caladaptr-res/main/geoms/ca_bnd.geojson\" ca_bnd_sf <- st_read(ca_bnd_url, quiet = TRUE) tm_shape(ca_bnd_sf) + tm_borders() + tm_grid(labels.show = TRUE, lines = FALSE) ca_bnd_blocks_sf <- ca_biggeom_blocks(ca_bnd_sf, block_area_mi2 = 20000)  tm_shape(ca_bnd_sf) +   tm_borders(col = \"gray\") +   tm_shape(ca_bnd_blocks_sf) +   tm_borders(col = \"red\") +   tm_text(\"id\")"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt3.html","id":"download-tifs","dir":"Articles","previous_headings":"","what":"Download TIFs","title":"Rasters Part III: Downloading Rasters for Large Areas","text":"first step download TIFs construct API request. ’ll make request yearly precipitation totals 50 years, 2 emissions scenarios, 4 GCMs:  Next download TIFs calling ca_getrst_stars(). may take minutes, don’t monitor .  TIP: good practice downloading large amounts data mindful gets saved, use overwrite = FALSE don’t download raster twice. ’re downloading data several projects / locations, create data download directory one TIFs blocked areas don’t get mixed .","code":"## Create a CAP ca_pr_cap <- ca_loc_sf(loc = ca_bnd_blocks_sf, idfld = \"id\") %>%   ca_gcm(gcms[1:4]) %>%   ca_period(\"year\") %>%   ca_cvar(\"pr\") %>%   ca_scenario(c(\"rcp45\", \"rcp85\")) %>%   ca_years(start = 2050, end = 2099)  ca_pr_cap %>% ca_preflight(check_for = \"getrst\") #> General issues #>  - none found #> Issues for downloading rasters #>  - none found data_dir <- tools::R_user_dir(\"caladaptr\", which = \"data\") ca_pryr_dir <- file.path(data_dir, \"ca_pr-year\") %>% normalizePath(mustWork = FALSE) if (!file.exists(ca_pryr_dir)) dir.create(ca_pryr_dir, recursive = TRUE)  ca_pryr_tifs <- ca_pr_cap %>%   ca_getrst_stars(out_dir = ca_pryr_dir, mask = TRUE, quiet = TRUE,                   normalize_path = TRUE, overwrite = FALSE)  ca_pryr_tifs %>% basename() %>% str() #>  chr [1:144] \"pr_year_HadGEM2-ES_rcp45_id-b01.tif\" \"pr_year_CNRM-CM5_rcp45_id-b01.tif\" \"pr_year_CanESM2_rcp45_id-b01.tif\" ..."},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt3.html","id":"import-tifs-and-mosaic-them","dir":"Articles","previous_headings":"","what":"Import TIFs and mosaic them","title":"Rasters Part III: Downloading Rasters for Large Areas","text":"’ve downloaded TIFs blocks, next step use ca_stars_read() import R list stars objects:  TIP: Monitoring memory usage. default mode importing stars objects read memory. Depending size study area, number layers, amount RAM computer, can potentially consume lot memory, extreme cases slow computer crawl. several packages can use monitor much memory different R objects using. see much memory object using base R, can run object.size(x) %>% format(units = \"Mb\"). stars objects big memory, can selective layers imported . Deleting objects longer needed can also help. Alternately can import TIFs stars proxy objects, passing proxy = TRUE ca_stars_read(). Stars proxy objects like pointers files disk, small. Data read actually needed analysis plotting. info, see vignette stars proxy objects.  point list 144 stars objects, representing several GCMs, scenarios, 18 blocks collectively cover California. ’s still pretty unwieldy, can mosaic ca_stars_mosaic(). return either list stars objects (combine_6d = FALSE, default), single stars object (combine_6d = TRUE). ’ll start creating list mosaiced rasters (default). list one 3D raster dataset (slug). geom_mask argument tells want mosaic returned masked original area--interest (case state boundary): list 144 stars objects reduced 8, covers entire state California. Let’s look properties first one: Plot first year:","code":"ca_pryr_blcks_stars_lst <- ca_pryr_tifs %>%   ca_stars_read()  length(ca_pryr_blcks_stars_lst) #> [1] 144  names(ca_pryr_blcks_stars_lst) %>% head(20) #>  [1] \"pr_year_HadGEM2-ES_rcp45_id-b01\" \"pr_year_CNRM-CM5_rcp45_id-b01\"   \"pr_year_CanESM2_rcp45_id-b01\"    \"pr_year_MIROC5_rcp45_id-b01\"     #>  [5] \"pr_year_HadGEM2-ES_rcp85_id-b01\" \"pr_year_CNRM-CM5_rcp85_id-b01\"   \"pr_year_CanESM2_rcp85_id-b01\"    \"pr_year_MIROC5_rcp85_id-b01\"     #>  [9] \"pr_year_HadGEM2-ES_rcp45_id-b02\" \"pr_year_CNRM-CM5_rcp45_id-b02\"   \"pr_year_CanESM2_rcp45_id-b02\"    \"pr_year_MIROC5_rcp45_id-b02\"     #> [13] \"pr_year_HadGEM2-ES_rcp85_id-b02\" \"pr_year_CNRM-CM5_rcp85_id-b02\"   \"pr_year_CanESM2_rcp85_id-b02\"    \"pr_year_MIROC5_rcp85_id-b02\"     #> [17] \"pr_year_HadGEM2-ES_rcp45_id-b03\" \"pr_year_CNRM-CM5_rcp45_id-b03\"   \"pr_year_CanESM2_rcp45_id-b03\"    \"pr_year_MIROC5_rcp45_id-b03\" ca_pryr_blcks_mos_lst <- ca_pryr_blcks_stars_lst %>%   ca_stars_mosaic(geom_mask = ca_bnd_sf) #>  - mosaicing 18 stars rasters for pr_year_HadGEM2-ES_rcp45 #>  - mosaicing 18 stars rasters for pr_year_CNRM-CM5_rcp45 #>  - mosaicing 18 stars rasters for pr_year_CanESM2_rcp45 #>  - mosaicing 18 stars rasters for pr_year_MIROC5_rcp45 #>  - mosaicing 18 stars rasters for pr_year_HadGEM2-ES_rcp85 #>  - mosaicing 18 stars rasters for pr_year_CNRM-CM5_rcp85 #>  - mosaicing 18 stars rasters for pr_year_CanESM2_rcp85 #>  - mosaicing 18 stars rasters for pr_year_MIROC5_rcp85  names(ca_pryr_blcks_mos_lst) #> [1] \"pr_year_HadGEM2-ES_rcp45\" \"pr_year_CNRM-CM5_rcp45\"   \"pr_year_CanESM2_rcp45\"    \"pr_year_MIROC5_rcp45\"     \"pr_year_HadGEM2-ES_rcp85\" #> [6] \"pr_year_CNRM-CM5_rcp85\"   \"pr_year_CanESM2_rcp85\"    \"pr_year_MIROC5_rcp85\" ca_pryr_blcks_mos_lst[[1]] #> stars object with 3 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>                                   Min.     1st Qu.      Median        Mean      3rd Qu.         Max.  NA's #> pr_year_HadGEM2-ES_rcp45  2.348845e-07 7.36848e-06 1.62481e-05 2.30751e-05 3.314904e-05 0.0001480115 57527 #> dimension(s): #>      from  to offset   delta refsys x/y #> x       1 165 -124.4  0.0625 WGS 84 [x] #> y       1 153  42.06 -0.0625 WGS 84 [y] #> year    1  50   2050       1     NA plot(ca_pryr_blcks_mos_lst[[1]] %>% filter(year == 2050), axes = TRUE, reset = FALSE) plot(ca_bnd_sf %>% st_geometry(), border = \"red\", lwd = 2, axes = TRUE, add = TRUE)"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt3.html","id":"create-a-6d-mosaic","dir":"Articles","previous_headings":"","what":"Create a 6D mosaic","title":"Rasters Part III: Downloading Rasters for Large Areas","text":"Next, ’ll mosaic 144 3D rasters , time ’ll add combine_6d = TRUE tell want single 6D stars object back: discussion examples working 6D climate cubes, see Rasters Part 2 vignette. Compute inter-annual variance precipitation. One potential impacts climate change increased variability precipitation. calculation tell us relatively speaking parts state may experience inter-annual variance precipitation 2050-2099. can plot results GCM one emissions scenario. TIP: Note use adrop() , drops dimensions range 1. useful case stars plot() function creates subplots level first non-spatial dimension. Therefore want get rid non-spatial dimensions range 1 (like cvar scenario), subplots made first remaining dimension multiple values (case GCM).","code":"ca_pryr_blcks_mos_stars <- ca_pryr_blcks_stars_lst %>%   ca_stars_mosaic(geom_mask = ca_bnd_sf, combine_6d = TRUE) #>  - mosaicing 18 stars rasters for pr_year_HadGEM2-ES_rcp45 #>  - mosaicing 18 stars rasters for pr_year_CNRM-CM5_rcp45 #>  - mosaicing 18 stars rasters for pr_year_CanESM2_rcp45 #>  - mosaicing 18 stars rasters for pr_year_MIROC5_rcp45 #>  - mosaicing 18 stars rasters for pr_year_HadGEM2-ES_rcp85 #>  - mosaicing 18 stars rasters for pr_year_CNRM-CM5_rcp85 #>  - mosaicing 18 stars rasters for pr_year_CanESM2_rcp85 #>  - mosaicing 18 stars rasters for pr_year_MIROC5_rcp85  ca_pryr_blcks_mos_stars #> stars object with 6 dimensions and 1 attribute #> attribute(s), summary of first 1e+05 cells: #>              Min.      1st Qu.       Median         Mean     3rd Qu.         Max.  NA's #> val  2.348845e-07 9.056052e-06 2.114469e-05 2.904023e-05 4.29896e-05 0.0001875527 57527 #> dimension(s): #>          from  to offset   delta refsys                values x/y #> x           1 165 -124.4  0.0625 WGS 84                  NULL [x] #> y           1 153  42.06 -0.0625 WGS 84                  NULL [y] #> scenario    1   2     NA      NA     NA          rcp45, rcp85     #> gcm         1   4     NA      NA     NA HadGEM2-ES,...,MIROC5     #> year        1  50   2050       1     NA                  NULL     #> cvar        1   1     NA      NA     NA                    pr (ca_pryr_sd_stars <- ca_pryr_blcks_mos_stars %>%   st_apply(MARGIN = c(\"x\", \"y\", \"scenario\", \"gcm\", \"cvar\"),            FUN = sd)) #> stars object with 5 dimensions and 1 attribute #> attribute(s): #>             Min.      1st Qu.       Median         Mean      3rd Qu.         Max.   NA's #> sd  5.237296e-07 2.693959e-06 5.454798e-06 7.165256e-06 1.023519e-05 4.661779e-05 116688 #> dimension(s): #>          from  to offset   delta refsys                values x/y #> x           1 165 -124.4  0.0625 WGS 84                  NULL [x] #> y           1 153  42.06 -0.0625 WGS 84                  NULL [y] #> scenario    1   2     NA      NA     NA          rcp45, rcp85     #> gcm         1   4     NA      NA     NA HadGEM2-ES,...,MIROC5     #> cvar        1   1     NA      NA     NA                    pr plot(ca_pryr_sd_stars %>% filter(scenario == \"rcp85\") %>% adrop(),       main = \"StdDev Annual Precip | RCP85 |\")"},{"path":"https://ucanr-igis.github.io/caladaptr/articles/rasters-pt3.html","id":"parallel-processing","dir":"Articles","previous_headings":"","what":"Parallel Processing","title":"Rasters Part III: Downloading Rasters for Large Areas","text":"st_apply() supports parallelization thru parallel package, comes base R. Parallelization splits work among different cores computer (computers days multipore cores). can improve performance pixelwise operations, particularly aggregation function computationally intensive (info). Let’s compare amount time takes compute standard deviation inter-annual precipitation, without parallelization, computer can bring 6 cores service:","code":"## Without parallelization system.time(ca_pryr_blcks_mos_stars %>%   st_apply(MARGIN = c(\"x\", \"y\", \"scenario\", \"gcm\", \"cvar\"),            FUN = sd)) #>    user  system elapsed  #>    1.83    0.00    1.86  ## With parallelization library(parallel) my_clust <- makeCluster(6) system.time(ca_pryr_blcks_mos_stars %>%   st_apply(MARGIN = c(\"x\", \"y\", \"scenario\", \"gcm\", \"cvar\"),            FUN = sd,            CLUSTER = my_clust)) #>    user  system elapsed  #>    0.56    0.41    1.15 stopCluster(my_clust)"},{"path":"https://ucanr-igis.github.io/caladaptr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Andy Lyons. Author, maintainer. Regents University California. Copyright holder. . Funder.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Andrew Lyons R Development Core Team (2025). caladaptr: Tools Cal-Adapt API R. R package version 0.7.0. https://ucanr-igis.github.io/caladaptr","code":"@Manual{,   title = {caladaptr: Tools for the Cal-Adapt API in R},   author = {Andrew Lyons and {R Development Core Team}},   year = {2025},   note = {R package version 0.7.0},   url = {https://ucanr-igis.github.io/caladaptr}, }"},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Import Climate Data from Cal-Adapt via the API","text":"caladaptr API client makes easier work data Cal-Adapt.org R. niche caladaptr bring data R can use packages analysis visualization:  caladaptr allows : query Cal-Adapt’s ~935 raster data layers retrieve values point, preset area--interest (e.g., census tract), user-provided polygon cache large queries local SQLite database download cropped rasters TIFs import R stars objects caladaptr functions designed : pipe friendly return tibbles compatibility tidyverse packages return values encoded units (managed units package) accept return sf data frames spatial objects needed return rasters spatiotemporal arrays (stars objects) caladaptr support downloading original NetCDF rasters station data (e.g., sea level rise, stream gauges). data, see Data Download tool FTP server Cal-Adapt.org.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Import Climate Data from Cal-Adapt via the API","text":"caladaptr available r-universe. install , can run: Alternately, can install directly GitHub. (requires remotes package plus RTools Windows users.) trying (failing) install caladaptr RStudio Cloud (another Linux machine), try install sf , caladaptr.","code":"options(repos = c(ajlyons = 'https://ajlyons.r-universe.dev',                   CRAN = 'https://cloud.r-project.org')) install.packages('caladaptr') remotes::install_github(\"ucanr-igis/caladaptr\") if (!require(sf)) install.packages(\"sf\") options(repos = c(ajlyons = 'https://ajlyons.r-universe.dev',                   CRAN = 'https://cloud.r-project.org')) install.packages('caladaptr')"},{"path":"https://ucanr-igis.github.io/caladaptr/index.html","id":"general-workflow","dir":"","previous_headings":"","what":"General Workflow","title":"Import Climate Data from Cal-Adapt via the API","text":"general, three steps retrieving Cal-Adapt data caladaptr: Create ‘API request object’ Feed API request function fetches data (either values rasters) Wrangle data comes back format required analysis","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/index.html","id":"example-projected-annual-temperature-at-a-point-location","dir":"","previous_headings":"","what":"Example: Projected Annual Temperature at a Point Location","title":"Import Climate Data from Cal-Adapt via the API","text":"example, ’ll get projected maximum daily temperature point location near Sacramento, averaged calendar year 2040-2070, 10 GCMs 2 emissions scenarios. ’ll plot . 1. Create API request object Creating API request object bit like filling order form. request essentially description data want. number constructor functions can mix match create API request object. create request 30 years projected annual average maximum daily temperature LOCA downscaled CMIP5 climate projections Scripps, single point location. 2. Fetch data Functions fetch data Cal-Adapt include ca_getvals_tbl(), ca_getvals_db() (see Large Queries vignette), ca_getrst_stars() (see Rasters Part vignette). ’ll fetch data tibble passing API request ca_getvals_tbl(): 3. Wrangle Data Depending goal , may need add delete columns, reshape data, group rows, etc. ’ll add column Fahrenheit using set_units() units package. Now can plot :","code":"library(caladaptr) #> caladaptr (version 0.7.0) #> URL: https://ucanr-igis.github.io/caladaptr #> Bug reports: https://github.com/ucanr-igis/caladaptr/issues  sac_tasmax_cap <- ca_loc_pt(coords = c(-121.4687, 38.5938)) %>%     ## specify a location   ca_gcm(c(\"HadGEM2-ES\", \"CNRM-CM5\", \"CanESM2\",\"MIROC5\",            ## select GCM(s)            \"ACCESS1-0\", \"CCSM4\", \"CESM1-BGC\",             \"CMCC-CMS\", \"GFDL-CM3\", \"HadGEM2-CC\")) %>%        ca_scenario(c(\"rcp45\",\"rcp85\")) %>%                               ## select emission scenarios(s)   ca_cvar(c(\"tasmax\")) %>%                                          ## select climate variables   ca_period(\"year\") %>%                                             ## select a temporal aggregation period   ca_years(start = 2040, end = 2070)                                ## select start and end dates  sac_tasmax_cap #> Cal-Adapt API Request #> Location(s):  #>   x: -121.469 #>   y: 38.594 #> Variable(s): tasmax #> Temporal aggregration period(s): year #> GCM(s): HadGEM2-ES, CNRM-CM5, CanESM2, MIROC5, ACCESS1-0, CCSM4, CESM1-BGC, CMCC-CMS, GFDL-CM3, HadGEM2-CC #> Scenario(s): rcp45, rcp85 #> Dates: 2040-01-01 to 2070-12-31 #> sac_tasmax_tbl <- sac_tasmax_cap %>% ca_getvals_tbl(quiet = TRUE) head(sac_tasmax_tbl) #> # A tibble: 6 × 8 #>      id cvar   period gcm        scenario spag  dt          val #>   <int> <fct>  <fct>  <fct>      <fct>    <fct> <chr>       [K] #> 1     1 tasmax year   HadGEM2-ES rcp45    none  2040-12-31 299. #> 2     1 tasmax year   HadGEM2-ES rcp45    none  2041-12-31 299. #> 3     1 tasmax year   HadGEM2-ES rcp45    none  2042-12-31 299. #> 4     1 tasmax year   HadGEM2-ES rcp45    none  2043-12-31 300. #> 5     1 tasmax year   HadGEM2-ES rcp45    none  2044-12-31 300. #> 6     1 tasmax year   HadGEM2-ES rcp45    none  2045-12-31 298. dim(sac_tasmax_tbl) #> [1] 620   8 ## Add a column with Fahrenheit units library(dplyr) library(units) sac_tasmax_tbl2 <- sac_tasmax_tbl %>% mutate(temp_f = set_units(val, degF)) head(sac_tasmax_tbl2) #> # A tibble: 6 × 9 #>      id cvar   period gcm        scenario spag  dt          val temp_f #>   <int> <fct>  <fct>  <fct>      <fct>    <fct> <chr>       [K] [degF] #> 1     1 tasmax year   HadGEM2-ES rcp45    none  2040-12-31 299.   78.1 #> 2     1 tasmax year   HadGEM2-ES rcp45    none  2041-12-31 299.   78.0 #> 3     1 tasmax year   HadGEM2-ES rcp45    none  2042-12-31 299.   77.8 #> 4     1 tasmax year   HadGEM2-ES rcp45    none  2043-12-31 300.   79.7 #> 5     1 tasmax year   HadGEM2-ES rcp45    none  2044-12-31 300.   79.5 #> 6     1 tasmax year   HadGEM2-ES rcp45    none  2045-12-31 298.   77.2 library(ggplot2) ggplot(data = sac_tasmax_tbl2,         aes(x = as.Date(dt), y = as.numeric(temp_f))) +   geom_line(aes(color=gcm)) +   facet_grid(scenario ~ .) +   labs(title = \"Annual Average Maximum Daily Temperature for Sacramento\", x = \"year\", y = \"temp (F)\")"},{"path":"https://ucanr-igis.github.io/caladaptr/index.html","id":"constructing-api-requests","dir":"","previous_headings":"","what":"Constructing API Requests","title":"Import Climate Data from Cal-Adapt via the API","text":"API request objects constructed stringing together functions provide key elements request, including location(s), dataset(s), time frame. Location functions (pick one): Date functions (pick one): Dataset functions (pick one group): ca_example_apireq() convenience function returns sample API requests testing. can use ca_preflight() check API request errors. Plotting API request show location(s), option overlay loca grid cells:  examples, including retrieving data preset area--interest (.e., census tracts), see API Requests vignette ‘R Notebooks’ website.","code":"samp_cap <- ca_example_apireq(3) samp_cap %>% ca_preflight() #> General issues #>  - none found #> Issues for querying values #>  - none found #> Issues for downloading rasters #>  - none found plot(samp_cap, locagrid = TRUE, static = TRUE)"},{"path":"https://ucanr-igis.github.io/caladaptr/index.html","id":"constants","dir":"","previous_headings":"","what":"Constants","title":"Import Climate Data from Cal-Adapt via the API","text":"help pass arguments various constructor functions, caladaptr provides following constants:","code":"## Climate Variables  cvars #>  [1] \"tasmax\"     \"tasmin\"     \"pr\"         \"swe\"        \"baseflow\"   #>  [6] \"et\"         \"rainfall\"   \"runoff\"     \"snowfall\"   \"soilMoist1\" #> [11] \"Tair\"  ## Global Climate Models ## Note: the first 4 are the 'priority' models recommended under California's 4th Climate Change Assessment. gcms #>  [1] \"HadGEM2-ES\" \"CNRM-CM5\"   \"CanESM2\"    \"MIROC5\"     \"ACCESS1-0\"  #>  [6] \"CCSM4\"      \"CESM1-BGC\"  \"CMCC-CMS\"   \"GFDL-CM3\"   \"HadGEM2-CC\" #> [11] \"ens32avg\"   \"ens32max\"   \"ens32min\"  ## Emission scenarios scenarios #> [1] \"rcp45\"      \"rcp85\"      \"historical\"  ## Temporal resolution periods periods #> [1] \"day\"    \"month\"  \"year\"   \"30yavg\""},{"path":"https://ucanr-igis.github.io/caladaptr/index.html","id":"data-catalog","dir":"","previous_headings":"","what":"Data Catalog","title":"Import Climate Data from Cal-Adapt via the API","text":"caladaptr can tell climate data need project. teach use climate data appropriately wisely. However copy Cal-Adapt raster series data catalog, can see ’s available specify datasets need. view entire data catalog RStudio Viewer pane, run following. can use filter button find datasets match key word. can also search datasets using ca_catalog_search(), download fresh copy catalog Cal-Adapt using ca_catalog_fetch(). / Cal-Adapt rasters series downscaled approximately 6km (3.7 mi) using LOCA downscaling method, available coverage area shown . finer scale analysis, can download LOCA grid cells polygon layer using ca_locagrid_geom().","code":"View(ca_catalog_rs())"},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://ucanr-igis.github.io/caladaptr/reference/aoipreset_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Area-of-interest presets — aoipreset_types","title":"Area-of-interest presets — aoipreset_types","text":"Area interest presets field(s) AOI Preset provides identify features Values can used identify features AOI Preset","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/aoipreset_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area-of-interest presets — aoipreset_types","text":"","code":"data(aoipreset_types)  data(aoipreset_idflds)  data(aoipreset_idval)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/aoipreset_types.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Area-of-interest presets — aoipreset_types","text":"character vector names area--interest presets Named list one element per preset type Named list data frames, one element per preset type","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/aoipreset_types.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Area-of-interest presets — aoipreset_types","text":"aoipreset_idflds: AOI Preset id fields aoipreset_idval: Values can used identify features","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/bbox_resize.html","id":null,"dir":"Reference","previous_headings":"","what":"Resize a bounding box object — bbox_resize","title":"Resize a bounding box object — bbox_resize","text":"Resize bounding box object scale factor buffer distance","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/bbox_resize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resize a bounding box object — bbox_resize","text":"","code":"bbox_resize(x, scale = NULL, buff = NULL)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/bbox_resize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resize a bounding box object — bbox_resize","text":"x bbox object scale scale factor buff buffer distance","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/bbox_resize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Resize a bounding box object — bbox_resize","text":"can resize bounding box passing value scale buff, . Use scale resize bounding box scale factor. Values scale < 1 result smaller bounding box, values > 1 result larger bounding box. centroid remain . pass two values scale, used scale x y dimensions respectively Use buff resize bounding box fixed distance. buff map units. Values buff < 0 result smaller bounding box. Values > 0 result larger bounding box. pass two values buff, used buffer x y dimensions respectively","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_aoipreset_geom.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the geometry of an AOI Preset area — ca_aoipreset_geom","title":"Get the geometry of an AOI Preset area — ca_aoipreset_geom","text":"Get geometry AOI Preset area","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_aoipreset_geom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the geometry of an AOI Preset area — ca_aoipreset_geom","text":"","code":"ca_aoipreset_geom(aoipreset, quiet = FALSE)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_aoipreset_geom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the geometry of an AOI Preset area — ca_aoipreset_geom","text":"aoipreset name AOI preset quiet Suppress messages","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_aoipreset_geom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the geometry of an AOI Preset area — ca_aoipreset_geom","text":"simple feature data frame","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_aoipreset_geom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the geometry of an AOI Preset area — ca_aoipreset_geom","text":"retrieves geometry (.e., boundaries) one Cal-Adapt's AOI Presets. spatial layer already downloaded, downloaded (https://github.com/ucanr-igis/caladaptr/tree/master/aoipreset_geoms) saved local cache directory GeoPackage. default local cache directory buried current user's 'AppData' folder. put GeoPackages easier--find location, use ca_setcache.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_apicalls.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a tibble of individual API calls — ca_apicalls","title":"Creates a tibble of individual API calls — ca_apicalls","text":"Constructs tibble individual API calls API request","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_apicalls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a tibble of individual API calls — ca_apicalls","text":"","code":"ca_apicalls(   x,   slug_check = TRUE,   date_check = TRUE,   loc_check = TRUE,   units_check = TRUE,   spag_check = FALSE,   pf = FALSE,   check_for = c(\"getvals\", \"getrst\"),   ignore_spag = deprecated(),   preflight = deprecated() )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_apicalls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a tibble of individual API calls — ca_apicalls","text":"x Cal-Adapt API request slug_check Cross check slug raster series catalog date_check Cross check start end date raster series catalog loc_check Check locations duplicate values Cal-Adapt coverage area units_check Check consistent units spag_check Check spatial aggregation option pf Run preflight check , logical check_for operations context use ignore_spag Deprecated preflight Deprecated","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_apicalls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a tibble of individual API calls — ca_apicalls","text":"pf = TRUE, list three types errors / issues discovered: ) general errors, ii) problems specific querying values, iii) problems specific downloading rasters.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_apicalls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates a tibble of individual API calls — ca_apicalls","text":"internal function ) evaluates API request generates tibble individual API calls, b) checks errors. exported may use trouble-shooting developers, something users need. function called two contexts: ) ca_preflight() report errors user b) data fetching functions (ca_getvals_tbl, ca_getvals_db, ca_getrst_stars), loop tibble returned fetch data","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_apireq.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a new API request object — ca_apireq","title":"Creates a new API request object — ca_apireq","text":"Creates new API request object","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_apireq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a new API request object — ca_apireq","text":"","code":"ca_apireq(   loc = NA,   dates = NA,   gcm = NA,   scenario = NA,   period = NA,   cvar = NA,   livneh = NA,   slug = NA,   options = NA )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_apireq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a new API request object — ca_apireq","text":"loc location object (see Details) dates dates object (see Details) gcm vector GCM abbreviations (see `gcms`) scenario vector scenario names (see `scenarios`) period vector period names (see `periods`) cvar vector climate variables (see `climvars`) livneh Use Livneh dataset, logical slug vector slugs options list options querying API","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_baseurl.html","id":null,"dir":"Reference","previous_headings":"","what":"Cal-Adapt base URL — ca_baseurl","title":"Cal-Adapt base URL — ca_baseurl","text":"Base URL calls Cal-Adapt API","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_baseurl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cal-Adapt base URL — ca_baseurl","text":"","code":"data(ca_baseurl)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_baseurl.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cal-Adapt base URL — ca_baseurl","text":"character vector","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_biggeom_blocks.html","id":null,"dir":"Reference","previous_headings":"","what":"Split a large geom into blocks small enough to ask the API for rasters — ca_biggeom_blocks","title":"Split a large geom into blocks small enough to ask the API for rasters — ca_biggeom_blocks","text":"Split large geom blocks small enough ask API rasters","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_biggeom_blocks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split a large geom into blocks small enough to ask the API for rasters — ca_biggeom_blocks","text":"","code":"ca_biggeom_blocks(x, block_area_mi2 = 18000)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_biggeom_blocks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split a large geom into blocks small enough to ask the API for rasters — ca_biggeom_blocks","text":"x big geom block_area_mi2 Maximum area block square miles. See details.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_biggeom_blocks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split a large geom into blocks small enough to ask the API for rasters — ca_biggeom_blocks","text":"polygon simple feature data frame covering extent x","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_biggeom_blocks.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Split a large geom into blocks small enough to ask the API for rasters — ca_biggeom_blocks","text":"Cal-Adapt API limit maximum area can download raster. function take sf object larger return blocks cover extent. Subsequently can download rasters individual blocks mosaic full area using ca_stars_mosaic. size limit API around 20,000 square miles (51,800 km2). default value `block_area_mi2` 18,000 mi^2 (46,600 km2) provide bit buffer. Smaller values result polygons. Note function can help work around maximum area can download tifs via API, help get spatially aggregated values large area using API. , need ) use function download rasters, b) mosaic , c) spatial aggregration large area--interest. study areas encompasses entire Cal-Adapt coverage area, better downloading individual rasters [Cal-Adapt Data Server](http://albers.cnr.berkeley.edu/data/).","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_biggeom_blocks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split a large geom into blocks small enough to ask the API for rasters — ca_biggeom_blocks","text":"","code":"if (FALSE) { # \\dontrun{   } # }"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_fetch.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch a new copy of the Cal-Adapt raster series catalog — ca_catalog_fetch","title":"Fetch a new copy of the Cal-Adapt raster series catalog — ca_catalog_fetch","text":"Fetch new copy Cal-Adapt raster series catalog","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_fetch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch a new copy of the Cal-Adapt raster series catalog — ca_catalog_fetch","text":"","code":"ca_catalog_fetch(quiet = FALSE, save_to_cache = TRUE)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_fetch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch a new copy of the Cal-Adapt raster series catalog — ca_catalog_fetch","text":"quiet Suppress messages, logical save_to_cache Save catalog cache directory, logical","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_fetch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch a new copy of the Cal-Adapt raster series catalog — ca_catalog_fetch","text":"raster series catalog tibble","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_fetch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fetch a new copy of the Cal-Adapt raster series catalog — ca_catalog_fetch","text":"function download list raster series available Cal-Adapt API. save_to_cache = TRUE, catalog saved csv file caladaptR's cache folder used subsequent calls ca_catalog_rs. copy raster series catalog also included caladaptR. can run ca_catalog_fetch() update catalog new raster series published Cal-Adapt. best way find new data published Cal-Adapt subscribe Cal-Adapt newsletter.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_rs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Cal-Adapt raster series data catalog — ca_catalog_rs","title":"Get the Cal-Adapt raster series data catalog — ca_catalog_rs","text":"Get local copy Cal-Adapt raster series data catalog","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_rs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Cal-Adapt raster series data catalog — ca_catalog_rs","text":"","code":"ca_catalog_rs(quiet = FALSE)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_rs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the Cal-Adapt raster series data catalog — ca_catalog_rs","text":"quiet Suppress messages","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_rs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the Cal-Adapt raster series data catalog — ca_catalog_rs","text":"tibble columns information raster series available Cal-Adapt API.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_rs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the Cal-Adapt raster series data catalog — ca_catalog_rs","text":"retrieves local copy Cal-Adapt 'catalog' raster series available Cal-Adapt API. copy catalog comes caladaptR. can also fetch new copy using ca_catalog_fetch.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_search.html","id":null,"dir":"Reference","previous_headings":"","what":"Search the Cal-Adapt raster series data catalog — ca_catalog_search","title":"Search the Cal-Adapt raster series data catalog — ca_catalog_search","text":"Search Cal-Adapt raster series data catalog","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search the Cal-Adapt raster series data catalog — ca_catalog_search","text":"","code":"ca_catalog_search(x, keep_together = FALSE, quiet = FALSE)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search the Cal-Adapt raster series data catalog — ca_catalog_search","text":"x text search keep_together treat x phrase, logical quiet suppress messages","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search the Cal-Adapt raster series data catalog — ca_catalog_search","text":"tibble information found raster series","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_search.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Search the Cal-Adapt raster series data catalog — ca_catalog_search","text":"function can used search local copy Cal-Adapt raster series data catalog, view properties matching results. Searched fields include dataset name slug. keep_together = TRUE, search text treated phrase, otherwise words x searched separately. Records match terms returned. online search tool, click 'Filters' button https://api.cal-adapt.org/api/series/.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_catalog_search.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search the Cal-Adapt raster series data catalog — ca_catalog_search","text":"","code":"if (FALSE) { # \\dontrun{ ## Search for a slug ca_catalog_search(\"pr_day_gridmet\")  ## Search for keywords ca_catalog_search(\"evapotranspiration year\")  ## Search for phrase ca_catalog_search(\"Livneh VIC\", keep_together = TRUE) } # }"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_cvar.html","id":null,"dir":"Reference","previous_headings":"","what":"Add climate variable(s) to a Cal-Adapt API request — ca_cvar","title":"Add climate variable(s) to a Cal-Adapt API request — ca_cvar","text":"Specifies climate variable(s) Cal-Adapt API call retrieve","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_cvar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add climate variable(s) to a Cal-Adapt API request — ca_cvar","text":"","code":"ca_cvar(x = ca_apireq(), cvar)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_cvar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add climate variable(s) to a Cal-Adapt API request — ca_cvar","text":"x Cal-Adapt API request cvar Climate variable","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_cvar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add climate variable(s) to a Cal-Adapt API request — ca_cvar","text":"valid options cvar, see cvars. Notes: 1) 'climate variables' refers variables returned global circulation models (e.g., temperature, precipitation), well variables derived additional models (e.g., evapo-transpiration) 2) climate variables available climate models, temporal periods, date ranges.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_dates.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a start and end date of a Cal-Adapt API call — ca_dates","title":"Adds a start and end date of a Cal-Adapt API call — ca_dates","text":"Specifies start end date Cal-Adapt API call","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_dates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a start and end date of a Cal-Adapt API call — ca_dates","text":"","code":"ca_dates(x = ca_apireq(), start, end)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_dates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a start and end date of a Cal-Adapt API call — ca_dates","text":"x Cal-Adapt API request start start date entered character yyyy-mm-dd Date object end end date entered character yyyy-mm-dd Date object","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_indices.html","id":null,"dir":"Reference","previous_headings":"","what":"Add or delete indices — ca_db_indices","title":"Add or delete indices — ca_db_indices","text":"Add delete indices","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_indices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add or delete indices — ca_db_indices","text":"","code":"ca_db_indices(x, tbl, idx_fld_add = NULL, idx_fld_del = NULL, quiet = FALSE)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_indices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add or delete indices — ca_db_indices","text":"x Either remote tibble SQLite database file name tbl name table SQLite database idx_fld_add Fields tbl create index idx_fld_del Fields tbl indices like delete quiet Suppress messages","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_indices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add or delete indices — ca_db_indices","text":"x","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_indices.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add or delete indices — ca_db_indices","text":"Database indices improve performance filter sort rows based field (column), /join tables based common field. default, indices created download Cal-Adapt data SQLite database ca_getvals_db (increase size SQLite file). can tell ca_getvals_db create indices indices argument, use ca_db_indices create indices data downloaded. x can either remote tibble returned ca_getvals_db, SQLite database file name. tbl name table database (.e., db_tbl argument passed ca_getvals_db. sure table names database, run ca_db_info. Normally add indices table contains values Cal-Adapt (need add indices lookup tables). can add indices one table time (idx_fld_add can contain multiple field names). Note ca_db_indices can create indices single field. create composite indices can run SQL expressions DBI package. Indices added ca_db_indices named automatically. details, see vignette querying large volumes data: vignette(\"large-queries\", package = \"caladaptr\")","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_info.html","id":null,"dir":"Reference","previous_headings":"","what":"View properties of a Cal-Adapt SQLlite database — ca_db_info","title":"View properties of a Cal-Adapt SQLlite database — ca_db_info","text":"View properties Cal-Adapt SQLlite database","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View properties of a Cal-Adapt SQLlite database — ca_db_info","text":"","code":"ca_db_info(x)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View properties of a Cal-Adapt SQLlite database — ca_db_info","text":"x Either Cal-Adapt values remote tibble SQLite database file name","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"View properties of a Cal-Adapt SQLlite database — ca_db_info","text":"list object info x, including tables, fields, indices, sql statements.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_info.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"View properties of a Cal-Adapt SQLlite database — ca_db_info","text":"x can either remote tibble returned ca_getvals_db, SQLite database file name.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_read.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a Cal-Adapt SQLite database into R — ca_db_read","title":"Load a Cal-Adapt SQLite database into R — ca_db_read","text":"Load Cal-Adapt SQLite database R","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_read.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a Cal-Adapt SQLite database into R — ca_db_read","text":"","code":"ca_db_read(   x,   val_tbl = NULL,   join_lookup_tbls = TRUE,   all_tables = FALSE,   exclude_hash_tables = TRUE )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_read.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a Cal-Adapt SQLite database into R — ca_db_read","text":"x Cal-Adapt values remote tibble SQLite file name val_tbl name table contains climate data, ignored all_tables = TRUE join_lookup_tbls Join lookup tables present remote tibble all_tables Return tables, logical exclude_hash_tables Exclude tables contain search hashes, ignored all_tables = FALSE","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_read.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a Cal-Adapt SQLite database into R — ca_db_read","text":"remote tibble climate values all_tables = FALSE, otherwise list remote tibbles all_tables = TRUE","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_db_read.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load a Cal-Adapt SQLite database into R — ca_db_read","text":"'mount' SQLite database created ca_getvals_db, return remote tibble (.e., tibble connected database). x can either SQLite file name remote tibble returned ca_getvals_db. val_tbl name table database contains climate values (.e., table specified ran ca_getvals_db). val_tbl = NULL sidecar text file SQLite database exists, search sidecar file name values table use first one. join_lookup_tbls = TRUE lookup tables used fetching data, remote tibble returned based SQL expression joins lookup tables values table. Joining lookup tables possible sidecar text file exists. all_tables = TRUE, list remote tibbles tables database returned. case, val_tbl join_lookup_tbls ignored. exclude_hash_tables = TRUE, tables store search hashes excluded returned list.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_example_apireq.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample API requests — ca_example_apireq","title":"Sample API requests — ca_example_apireq","text":"Sample API requests","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_example_apireq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample API requests — ca_example_apireq","text":"","code":"ca_example_apireq(x)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_example_apireq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample API requests — ca_example_apireq","text":"x number sample API request return","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_example_apireq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample API requests — ca_example_apireq","text":"sample API requests can used demos, documentation, tests. x integer: x = 1: Basic API request Scripps data – one point, 4 CGMs, 20 years annual data. x = 2: Three Congressional districts, monthly data, 4 years x = 3: sf data frame one feature, 1 GCM, 1 scenario, 2 years daily data x = 4: sf data frame two multipolygons, 1 GCM, 1 scenario, 20 years annual data x = 5: Livheh data, ten census tracts, 20 years daily temp data, spatial aggregation mean x = 6: Livheh data, five census tracts (including one #5), 5 years daily temp data, spatial aggregation = mean x = 7: Basic API request Scripps data – one point, 4 CGMs, 70 years annual data.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_gcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds GCM(s) to a Cal-Adapt API request — ca_gcm","title":"Adds GCM(s) to a Cal-Adapt API request — ca_gcm","text":"Specifies GCM(s) Cal-Adapt API call retrieve","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_gcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds GCM(s) to a Cal-Adapt API request — ca_gcm","text":"","code":"ca_gcm(x = ca_apireq(), gcm)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_gcm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds GCM(s) to a Cal-Adapt API request — ca_gcm","text":"x Cal-Adapt API request gcm Global Climate Model abbreviation","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_gcm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adds GCM(s) to a Cal-Adapt API request — ca_gcm","text":"valid options gcm, see gcms.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getcache.html","id":null,"dir":"Reference","previous_headings":"","what":"Manage cache directory — ca_getcache","title":"Manage cache directory — ca_getcache","text":"View set directory data catalog","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getcache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manage cache directory — ca_getcache","text":"","code":"ca_getcache(quiet = TRUE)  ca_setcache(   cache_dir = NULL,   make_dir = TRUE,   save = TRUE,   reset = FALSE,   quiet = FALSE )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getcache.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manage cache directory — ca_getcache","text":"quiet Suppress messages cache_dir directory cached data make_dir Make directory needed, logical save Save cache directory .Renviron file persistence across R sessions reset Change default location","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getcache.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Manage cache directory — ca_getcache","text":"caladaptr ability store copies objects downloaded Cal-Adapt. example raster series data catalog geometries AOI Presets. NOTE: general caladaptr cache climate data fetched Cal-Adapt. Every time call function fetches data (e.g., ca_getvals_tbl), data retrieved fresh. exception ca_getvals_db, arguments can pass cache retrieved values local SQLite database explicitly avoid downloading data twice. default location cache directory given R_user_dir(\"caladaptr\", \"cache\"). custom location can set ca_setcache.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getcache.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Manage cache directory — ca_getcache","text":"ca_setcache(): Set cache directory","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getrst_stars.html","id":null,"dir":"Reference","previous_headings":"","what":"Get cropped rasters — ca_getrst_stars","title":"Get cropped rasters — ca_getrst_stars","text":"Download cropped raster API request","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getrst_stars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get cropped rasters — ca_getrst_stars","text":"","code":"ca_getrst_stars(   x,   out_dir = NULL,   mask = TRUE,   merge_geoms = FALSE,   sidecar = TRUE,   stop_on_err = TRUE,   overwrite = FALSE,   normalize_path = FALSE,   debug = FALSE,   quiet = FALSE,   write_sidecar = deprecated() )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getrst_stars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get cropped rasters — ca_getrst_stars","text":"x Cal-Adapt API request out_dir output TIF files written mask Mask pixels outside location interest NA values merge_geoms Whether merge geometries, see Details sidecar Save small sidecar file TIF file containing additional attribute info stop_on_err Stop server returns error overwrite Re-download overwrite existing files normalize_path Expand normalize output file names debug Print additional output console quiet Suppress messages write_sidecar Deprecated","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getrst_stars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get cropped rasters — ca_getrst_stars","text":"vector TIF file names. normalize_path = TRUE output file names expanded (absolute) use standard slashes OS (see normalizePath).","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getrst_stars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get cropped rasters — ca_getrst_stars","text":"download time series cropped raster(s) study area, convert stars objects, export tif files. mask = TRUE, pixels values outside area interest set NA (mask ignored point locations). get single raster per dataset encompasses locations, pass merge_geoms = TRUE. Note work areas--interest small enough Cal-Adapt API handle (.e., smaller San Bernadino County). want download rasters large area (e.g., whole state California) better downloading NetCDF files Cal-Adapt data server. sidecar = TRUE, small file base name tif saved. sidecar file contains attributes space-time-array preserved tifs. can import tif file back R stars object ca_read_stars. function merely downloads cropped rasters disk returns filenames. work cropped rasters stars objects within R, import using ca_read_stars. can also import TIF files packages software.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getvals_db.html","id":null,"dir":"Reference","previous_headings":"","what":"Write values from an API request to a local database — ca_getvals_db","title":"Write values from an API request to a local database — ca_getvals_db","text":"Write values API request local database","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getvals_db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write values from an API request to a local database — ca_getvals_db","text":"","code":"ca_getvals_db(   x,   db_fn,   db_tbl,   omit_col = NULL,   indices = NULL,   new_recs_only = TRUE,   trans_len = 100,   lookup_tbls = TRUE,   lookup_ret_joined = TRUE,   pause_n = 1000,   pause_secs = 60,   write_sidecar = TRUE,   stop_on_err = TRUE,   quiet = FALSE,   debug = FALSE )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getvals_db.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write values from an API request to a local database — ca_getvals_db","text":"x Cal-Adapt API request db_fn File name SQLite database. See Details. db_tbl name database table. See Details. omit_col Columns exclude tibble indices Name fields index. See Details. new_recs_only Write new records database. See Details. trans_len Number APIs calls per write transaction. See Details. lookup_tbls Use lookup tables lookup_ret_joined Return table lookup table fields, ignored lookup_tbls = FALSE. See Details. pause_n Number API calls built-pause triggered. See Details. pause_secs Number seconds pause. See Details. write_sidecar Save table metadata separate file. See Details. stop_on_err Stop server returns error quiet Suppress messages debug Print additional output console","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getvals_db.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write values from an API request to a local database — ca_getvals_db","text":"remote tibble linked SQLite database.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getvals_db.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write values from an API request to a local database — ca_getvals_db","text":"ca_getvals_db fetches data Cal-Adapt API writes data SQLite database received. allows fetch relatively large volumes data background, potentially multiple sessions pick left interrupted. Saving values database also reduces risk exhausting RAM. Use ca_getvals_db fetch large volumes data (.e., hundreds thousands values), whenever like keep  local copy data. Note however small amounts data advantage putting database slighly slower retrieve work . db_fn file name path SQLite database. SQLIte database single file typically .db .sqlite extension. database exist, created. already exists, new data added . db_tbl name table within database new data saved. table name contain special characters spaces discouraged. new_recs_only = TRUE, new records added database. trans_len defines number API calls per SQLite transaction (.e. many API calls data accumulate write operation database). can speed things . Set 0 disable transactions. lookup_tbls = TRUE, database create lookup tables categorical columns GCM, scenario, cvar, period, slug, etc. can dramatically reduce size SQLite database file generally recommended. id lookup_ret_joined = TRUE, tibble returned lookup tables joined (.e., column names unaltered); returned tibble id values certain values. small text file created SQLite database containing names tables SQL statement join (read automatically ca_db_read). indices vector column names db_tbl like indexed (ignored lookup_tbls = FALSE). Creating indices can improve performance filters joins generate summaries, cost larger database file slightly slower write operations. Fields can create indices include \"feat_id\" (location id value), \"cvar\", \"gcm\", \"scenario\", \"period\", \"slug\", \"spag\". Indices can also added SQLite database downloading complete ca_db_indices. large queries (e.g. thousands API calls), recommended build indices download process, add indices fields plan filter join analysis. can view indices exist ca_db_info. pause_n number API calls built-pause length pause_secs triggered. intended avoid disruption Cal-Adapt server. maximum value pause_n 2500, minimum value pause_secs 30 seconds. returned tibble linked SQLite datbase. part can use dplyr functions manipulate results, retrieve actual values need use `collect()`. info working linked database, see https://dbplyr.tidyverse.org/articles/dbplyr.html.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getvals_tbl.html","id":null,"dir":"Reference","previous_headings":"","what":"Get values from an API request object as a tibble — ca_getvals_tbl","title":"Get values from an API request object as a tibble — ca_getvals_tbl","text":"Get values API request object tibble","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getvals_tbl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get values from an API request object as a tibble — ca_getvals_tbl","text":"","code":"ca_getvals_tbl(   x,   quiet = FALSE,   debug = FALSE,   stop_on_err = TRUE,   shiny_progress = NULL,   omit_col = NULL,   timeout = NULL )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getvals_tbl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get values from an API request object as a tibble — ca_getvals_tbl","text":"x Cal-Adapt API request quiet Suppress messages debug Print additional output console stop_on_err Stop server returns error shiny_progress Shiny progress bar object, see Details. omit_col Columns exclude tibble timeout Timeout limit seconds","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getvals_tbl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get values from an API request object as a tibble — ca_getvals_tbl","text":"tibble","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_getvals_tbl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get values from an API request object as a tibble — ca_getvals_tbl","text":"ca_getvals_tbl fetches data via Cal-Adapt API, returning tibble. Everything done memory. download Cal-Adapt local SQLite database, see ca_getvals_db. download Cal-Adapt data raster files, see ca_getrst_stars. default set columns returned based dataset specified (.e., slug, cvar+scen+gcm+per, livneh, etc). columns can omitted passing column names col_omit. Three columns can never omitted feat_id (location id value), dt (date), val (actual climate values). timeout set longest amount time curl reports error. default 10 seconds. Increase experience timeout errors (know occur ShinyApps.io perhaps due server congestion).","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_livneh.html","id":null,"dir":"Reference","previous_headings":"","what":"Use Livneh data in a Cal-Adapt API call — ca_livneh","title":"Use Livneh data in a Cal-Adapt API call — ca_livneh","text":"Specify Livneh data retrieved Cal-Adapt API call","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_livneh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use Livneh data in a Cal-Adapt API call — ca_livneh","text":"","code":"ca_livneh(x = ca_apireq(), livneh = TRUE)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_livneh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use Livneh data in a Cal-Adapt API call — ca_livneh","text":"x Cal-Adapt API request livneh Use Livneh data, logical","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_livneh.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Use Livneh data in a Cal-Adapt API call — ca_livneh","text":"Convenience function create API request object one Livneh datasets","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_locagrid_geom.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the LOCA grid cells as a sf object — ca_locagrid_geom","title":"Get the LOCA grid cells as a sf object — ca_locagrid_geom","text":"Get geometry LOCA grid cells sf polygon object","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_locagrid_geom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the LOCA grid cells as a sf object — ca_locagrid_geom","text":"","code":"ca_locagrid_geom(quiet = FALSE)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_locagrid_geom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the LOCA grid cells as a sf object — ca_locagrid_geom","text":"quiet Suppress messages","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_locagrid_geom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the LOCA grid cells as a sf object — ca_locagrid_geom","text":"simple feature data frame","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_locagrid_geom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the LOCA grid cells as a sf object — ca_locagrid_geom","text":"retrieves geometry LOCA grid vector (polygon) layer. cells grid represent pixels LOCA downscaled raster series Cal-Adapt. copy layer saved cache folder downloaded .","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_aoipreset.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a preset location to a Cal-Adapt API request — ca_loc_aoipreset","title":"Adds a preset location to a Cal-Adapt API request — ca_loc_aoipreset","text":"Adds preset location Cal-Adapt API request","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_aoipreset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a preset location to a Cal-Adapt API request — ca_loc_aoipreset","text":"","code":"ca_loc_aoipreset(x = ca_apireq(), type, idfld = \"id\", idval = NULL)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_aoipreset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a preset location to a Cal-Adapt API request — ca_loc_aoipreset","text":"x Cal-Adapt API request type type AOI preset (see Details) idfld name field identifies desired locations idval value(s) idfld","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_aoipreset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adds a preset location to a Cal-Adapt API request — ca_loc_aoipreset","text":"type specifies one preset areas interest supported Cal-Adapt API. valid values, view built-constant aoipreset_types. idfld field contains values want use select preset areas. list fields can use AOI preset, see built-list ca_aoipreset_idflds. idval value(s) can use select specific areas interest. list values, see built-list ca_aoipreset_idval. idval = NULL, areas used. Note AOI Presets supported Cal-Adapt API polygons. means order query values areas (.e., ca_getvals_tbl), must also specify spatial aggregation function using ca_options.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_pt.html","id":null,"dir":"Reference","previous_headings":"","what":"Add point location(s) to a Cal-Adapt API request — ca_loc_pt","title":"Add point location(s) to a Cal-Adapt API request — ca_loc_pt","text":"Specifies point location(s) Cal-Adapt API call retrieve","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_pt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add point location(s) to a Cal-Adapt API request — ca_loc_pt","text":"","code":"ca_loc_pt(x = ca_apireq(), coords, id = NULL)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_pt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add point location(s) to a Cal-Adapt API request — ca_loc_pt","text":"x Cal-Adapt API request coords two-column matrix data frame id Unique id values point","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_pt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add point location(s) to a Cal-Adapt API request — ca_loc_pt","text":"coords two-column matrix data frame first column containing x (longitude) values points interest, second column containing y (latitude) values. Projected coordinates can used function (see ca_loc_sf). id vector uniquely identify points. omitted, row numbers used.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_sf.html","id":null,"dir":"Reference","previous_headings":"","what":"Use a sf data frame as the location for a Cal-Adapt API request — ca_loc_sf","title":"Use a sf data frame as the location for a Cal-Adapt API request — ca_loc_sf","text":"Specifies sf data frame location Cal-Adapt API request","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_sf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use a sf data frame as the location for a Cal-Adapt API request — ca_loc_sf","text":"","code":"ca_loc_sf(x = ca_apireq(), loc, idfld = NULL, idval = NULL, dTolerance = 0)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_sf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use a sf data frame as the location for a Cal-Adapt API request — ca_loc_sf","text":"x Cal-Adapt API request loc simple feature data frame idfld name column loc containing unique values, name idval vector unique values dTolerance numeric value used simplify polgyons, see Details.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_loc_sf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Use a sf data frame as the location for a Cal-Adapt API request — ca_loc_sf","text":"loc simple feature data frame point polygon features. sf object valid CRS, geographic. 'single' 'multipart' polygons can used, simple point features supported. convert multipoint feature layer single point layer, use st_cast. idfld name column loc containing unique values. fetch values Cal-Adapt, column returned results help join values tables. Alternately, can use idfld pass name new column, together vector unique values idval (one row loc). Note can use idval filter. want filter features loc query, use filter expression part value loc (e.g., filter slice). loc polygon layer, also need specify spatially aggregate queried values feature overlaps one pixel. See ca_options. dTolerance value decimal degrees used simplify polygons. dTolerance > 0, geos_unary{st_simplify} called remove polygon nodes within dTolerance another node, fetching data. can reduce amount spatial data needs sent server, can improve performance particularly fine grained polygons. Simplifying polygons can modify (generally reduce) pixels polygon overlaps, use caution. dTolerance =\t0.001 represents <100m ground within Cal-Adapt range latitude.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Add processing options to a Cal-Adapt API call — ca_options","title":"Add processing options to a Cal-Adapt API call — ca_options","text":"Specify processing options Cal-Adapt API call","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add processing options to a Cal-Adapt API call — ca_options","text":"","code":"ca_options(   x = ca_apireq(),   spatial_ag = c(\"none\", \"mean\", \"max\", \"median\", \"min\", \"sum\")[1],   temporal_ag = NA )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add processing options to a Cal-Adapt API call — ca_options","text":"x Cal-Adapt API request spatial_ag Spatial aggregation function polygon locs. temporal_ag List object specifying unit time summary function(s) temporal aggregation. YET SUPPORTED","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add processing options to a Cal-Adapt API call — ca_options","text":"spatial_ag name(s) summary statistic(s) used querying polygon locations aggregate values pixel fall within area interest. Values can mean, max, median, min, sum. get retrieve individual values pixels without summary, use ca_getrst function. querying point locations (e.g., ca_loc_pt ca_loc_zip, spatial_ag set 'none'. temporal_ag allows apply additional temporal aggregation function, top temporal aggregation data already summarized (e.g., month year). querying climate layers already temporally aggregated, unit temporal aggregation must larger unit time (e.g., pull annual average layers try aggregate month).","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign temporal aggregation period to a Cal-Adapt API call — ca_period","title":"Assign temporal aggregation period to a Cal-Adapt API call — ca_period","text":"Add temporal aggregation period Cal-Adapt API request","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign temporal aggregation period to a Cal-Adapt API call — ca_period","text":"","code":"ca_period(x = ca_apireq(), period)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign temporal aggregation period to a Cal-Adapt API call — ca_period","text":"x Cal-Adapt API request period Period temporal aggregation","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_period.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Assign temporal aggregation period to a Cal-Adapt API call — ca_period","text":"valid options period, run periods. Notes:","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_preflight.html","id":null,"dir":"Reference","previous_headings":"","what":"Run checks on an API request object — ca_preflight","title":"Run checks on an API request object — ca_preflight","text":"Run checks API request object","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_preflight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run checks on an API request object — ca_preflight","text":"","code":"ca_preflight(   x,   slug_check = TRUE,   date_check = TRUE,   loc_check = TRUE,   units_check = TRUE,   spag_check = TRUE,   check_for = c(\"getvals\", \"getrst\"),   quiet = FALSE,   ignore_spag = deprecated() )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_preflight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run checks on an API request object — ca_preflight","text":"x Cal-Adapt API request slug_check Cross check slug raster series catalog date_check Cross check start end date raster series catalog loc_check Check make sure location within Cal-Adapt coverage area units_check Check consistent units spag_check Check spatial aggregation option check_for check - getting values getting rasters quiet Suppress messages ignore_spag Deprecated","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_preflight.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run checks on an API request object — ca_preflight","text":"TRUE messages reported, else FALSE","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_preflight.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run checks on an API request object — ca_preflight","text":"function checks Cal-Adapt API request potential problems. checks make sure request: complete conflicting elements specifies existing datasets specifies location within Cal-Adapt coverage area specifies area--interest presets correctly features large Cal-Adapt API mix datasets different units uses dates fall within Cal-Adapt time series includes spatial aggregation function needed checks can selectively disabled using arguments. check_for allows tailor checks querying values /downloading rasters.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_read_db.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a Cal-Adapt SQLite database into R — ca_read_db","title":"Load a Cal-Adapt SQLite database into R — ca_read_db","text":"`r lifecycle::badge(deprecated)` `ca_read_db()` renamed `ca_db_read()` consistent API.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_read_db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a Cal-Adapt SQLite database into R — ca_read_db","text":"","code":"ca_read_db(   x,   val_tbl = NULL,   join_lookup_tbls = TRUE,   all_tables = FALSE,   exclude_hash_tables = TRUE )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_read_stars.html","id":null,"dir":"Reference","previous_headings":"","what":"Read downloaded TIF files into R — ca_read_stars","title":"Read downloaded TIF files into R — ca_read_stars","text":"`r lifecycle::badge(deprecated)` `ca_read_stars()` renamed `ca_stars_read()` consistent API.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_read_stars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read downloaded TIF files into R — ca_read_stars","text":"","code":"ca_read_stars(x, read_sidecar = TRUE, proxy = FALSE)"},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_scenario.html","id":null,"dir":"Reference","previous_headings":"","what":"Add emission scenario(s) to a Cal-Adapt API request — ca_scenario","title":"Add emission scenario(s) to a Cal-Adapt API request — ca_scenario","text":"Specifies emission scenario(s) retrieval","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_scenario.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add emission scenario(s) to a Cal-Adapt API request — ca_scenario","text":"","code":"ca_scenario(x = ca_apireq(), scenario)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_scenario.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add emission scenario(s) to a Cal-Adapt API request — ca_scenario","text":"x Cal-Adapt API request scenario Abbreviation emissions scenario(s)","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_scenario.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add emission scenario(s) to a Cal-Adapt API request — ca_scenario","text":"valid options scenario, see scenarios.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_settings.html","id":null,"dir":"Reference","previous_headings":"","what":"Manage package settings — ca_settings","title":"Manage package settings — ca_settings","text":"View manage package settings","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_settings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manage package settings — ca_settings","text":"","code":"ca_settings(console_colors = NA, date_slice = NA, quiet = FALSE)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_settings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manage package settings — ca_settings","text":"console_colors name preset, list date_slice Whether use date slicing Cal-Adapt API available quiet Suppress messages, logical","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_settings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Manage package settings — ca_settings","text":"console_colors controls color text printed console. can pass name preset named list color functions (.e., crayon package). six styles recognized, see example . date_slice determines whether date slicing via URL construction used Cal-Adapt datasets support . generally good idea, can set FALSE trouble-shooting.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_settings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Manage package settings — ca_settings","text":"","code":"if (FALSE) { # \\dontrun{ ca_settings(console_colors = list(ca_accent1 = crayon::blue$bold,                                   ca_accent2 = crayon::magenta,                                   ca_accent3 = crayon::red$bold,                                   ca_accent4 = crayon::red,                                   ca_message = crayon::silver,                                   ca_success = crayon::green$bold)) } # }"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_slug.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds slug(s) to a Cal-Adapt API call — ca_slug","title":"Adds slug(s) to a Cal-Adapt API call — ca_slug","text":"Specify raster series slug Cal-Adapt API call retrieve","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_slug.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds slug(s) to a Cal-Adapt API call — ca_slug","text":"","code":"ca_slug(x = ca_apireq(), slug)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_slug.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds slug(s) to a Cal-Adapt API call — ca_slug","text":"x Cal-Adapt API request slug Raster series slug(s)","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_slug.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adds slug(s) to a Cal-Adapt API call — ca_slug","text":"find valid slugs, see ca_catalog_rs.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_6d.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a six-dimensional stars object for modeled climate data — ca_stars_6d","title":"Create a six-dimensional stars object for modeled climate data — ca_stars_6d","text":"Create six-dimensional stars object modeled climate data","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_6d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a six-dimensional stars object for modeled climate data — ca_stars_6d","text":"","code":"ca_stars_6d(stars_lst, index_tbl = NULL)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_6d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a six-dimensional stars object for modeled climate data — ca_stars_6d","text":"stars_lst list stars rasters index_tbl tibble metadata stars_lst","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_6d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a six-dimensional stars object for modeled climate data — ca_stars_6d","text":"six-dimensional stars object dimensions x, y, scenario, gcm, date, cvar","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_6d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a six-dimensional stars object for modeled climate data — ca_stars_6d","text":"stars_lst list stars objects downloaded ca_getrst_stars turned list ca_stars_read. Note functions must use `sidecar = TRUE`. Creating six-dimensional stars array projected climate data may useful writing compact expressions analysis. Six-dimensional arrays can constructed API request specifed GCM, scenario, climate variable. Rasters retrieved using API request specified dataset name slug can turned 6D arrays. Another requirement rasters location / extent.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_6d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a six-dimensional stars object for modeled climate data — ca_stars_6d","text":"","code":"if (FALSE) { # \\dontrun{   } # }"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an index for a list of stars rasters — ca_stars_index","title":"Create an index for a list of stars rasters — ca_stars_index","text":"Create index list stars rasters","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an index for a list of stars rasters — ca_stars_index","text":"","code":"ca_stars_index(x)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an index for a list of stars rasters — ca_stars_index","text":"x list stars rasters","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an index for a list of stars rasters — ca_stars_index","text":"tibble properties elements x. one row element x. Columns include cvar, scenario, gcm, period, slug, livneh, start, end, rows, cols.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_index.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an index for a list of stars rasters — ca_stars_index","text":"download rasters Cal-Adapt using ca_getrst_stars  ca_stars_index generates index properties elements list stars rasters help identify stars rasters contain climate model data.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an index for a list of stars rasters — ca_stars_index","text":"","code":"if (FALSE) { # \\dontrun{ ## Download 5 years of daily max and min temp for Merced County as rasters mercd_cap <- ca_loc_aoipreset(type = \"counties\", idfld = \"fips\", idval = \"06047\") %>%   ca_gcm(gcms[1:2]) %>%   ca_period(\"day\") %>%   ca_cvar(c(\"tasmin\", \"tasmax\")) %>%   ca_scenario(\"rcp45\") %>%   ca_years(start = 2060, end = 2065)  mercd_stars_lst <- mercd_cap %>%   ca_getrst_stars(out_dir = \".\") %>%   ca_read_stars()  ## Create an index tibble to see the climate model in each stars raster mercd_stars_tbl <- mercd_stars_lst %>%   ca_starslist_index() } # }"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_mosaic.html","id":null,"dir":"Reference","previous_headings":"","what":"Mosaic stars objects into a seamless array for large areas — ca_stars_mosaic","title":"Mosaic stars objects into a seamless array for large areas — ca_stars_mosaic","text":"Mosaic stars objects seamless array large areas","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_mosaic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mosaic stars objects into a seamless array for large areas — ca_stars_mosaic","text":"","code":"ca_stars_mosaic(   stars_lst,   index_tbl = NULL,   geom_mask = NULL,   combine_6d = FALSE,   quiet = FALSE )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_mosaic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mosaic stars objects into a seamless array for large areas — ca_stars_mosaic","text":"stars_lst list stars rasters index_tbl tibble metadata stars_lst geom_mask sf sfc polygon object crop mosaiced raster combine_6d Combine multiple 3D rasters one 6D raster quiet Suppress messages","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_mosaic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mosaic stars objects into a seamless array for large areas — ca_stars_mosaic","text":"combine_6d = FALSE, list 3D rasters returned (x, y date/year). combine_6d = TRUE, 6D stars raster returned (x, y, date/year, scenario, GCM, climate variable).","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_mosaic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mosaic stars objects into a seamless array for large areas — ca_stars_mosaic","text":"stars_lst list stars objects downloaded ca_getrst_stars turned list ca_stars_read. Note functions must run `sidecar = TRUE` (default). combine_6d = TRUE return mosaic six-dimensional raster. requires raster originally downloaded using API request specified dataset scenario, GCM, climate variable (.e., slug).","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_mosaic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mosaic stars objects into a seamless array for large areas — ca_stars_mosaic","text":"","code":"if (FALSE) { # \\dontrun{  } # }"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_read.html","id":null,"dir":"Reference","previous_headings":"","what":"Read tif files from disk — ca_stars_read","title":"Read tif files from disk — ca_stars_read","text":"Read tif files disk","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_read.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read tif files from disk — ca_stars_read","text":"","code":"ca_stars_read(x, sidecar = TRUE, proxy = FALSE)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_read.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read tif files from disk — ca_stars_read","text":"x File name(s) path tif files sidecar Read sidecar files exist, logical proxy Import TIF file stars proxy","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_read.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read tif files from disk — ca_stars_read","text":"list stars objects","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_stars_read.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read tif files from disk — ca_stars_read","text":"function can used read tif files downloaded ca_getrst_stars. lightweight wrapper around stars::read_stars(), ability read sidecar files created ca_getrst_stars. sidecar files restore attributes array dimensions otherwise preserved tif format. proxy signifies whether tif file(s) read stars proxy (e.g., pointer). recommended rasters potentially large fit memory. stars proxy objects, rasters read memory needed, cost potentially slightly slower performance. details see stars documentation.","code":""},{"path":[]},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_years.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds the start and end year to a Cal-Adapt API call — ca_years","title":"Adds the start and end year to a Cal-Adapt API call — ca_years","text":"Specifies start end year Cal-Adapt API call","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_years.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds the start and end year to a Cal-Adapt API call — ca_years","text":"","code":"ca_years(x = ca_apireq(), start, end)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/ca_years.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds the start and end year to a Cal-Adapt API call — ca_years","text":"x Cal-Adapt API request start start year end end year","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/cvars.html","id":null,"dir":"Reference","previous_headings":"","what":"Climate variables — cvars","title":"Climate variables — cvars","text":"Climate variables available raster series","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/cvars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Climate variables — cvars","text":"","code":"data(cvars)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/cvars.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Climate variables — cvars","text":"character vector names climate variables","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/cvars.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Climate variables — cvars","text":"https://berkeley-gif.github.io/caladapt-docs/data-catalog.html#climate-variables","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/cvars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Climate variables — cvars","text":"following climate variables available raster series thru Cal-Adapt API. tasmax: Maximum Temperature (historical values UW Hydro forecast values LOCA downscaled climate projections) tasmin: Minimum Temperature (historical values UW Hydro forecast values LOCA downscaled climate projections) pr: Precipitation (historical values UW Hydro forecast values LOCA downscaled climate projections)","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/format.ca_apireq.html","id":null,"dir":"Reference","previous_headings":"","what":"Format a ca_apireq object — format.ca_apireq","title":"Format a ca_apireq object — format.ca_apireq","text":"Format ca_apireq object","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/format.ca_apireq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format a ca_apireq object — format.ca_apireq","text":"","code":"# S3 method for class 'ca_apireq' format(x, ...)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/format.ca_apireq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format a ca_apireq object — format.ca_apireq","text":"x Cal-Adapt API request ... Unused","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/format.ca_db_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Format a ca_db_info object for printing at the console — format.ca_db_info","title":"Format a ca_db_info object for printing at the console — format.ca_db_info","text":"Format ca_db_info object printing console","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/format.ca_db_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format a ca_db_info object for printing at the console — format.ca_db_info","text":"","code":"# S3 method for class 'ca_db_info' format(x, ...)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/format.ca_db_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format a ca_db_info object for printing at the console — format.ca_db_info","text":"x object class ca_db_info ... Unused","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/gcms.html","id":null,"dir":"Reference","previous_headings":"","what":"Global climate models — gcms","title":"Global climate models — gcms","text":"Global Climate Models available Cal-Adapt API","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/gcms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global climate models — gcms","text":"","code":"data(gcms)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/gcms.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Global climate models — gcms","text":"character vector names 10 GCMs (abbreviated)","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/gcms.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Global climate models — gcms","text":"https://berkeley-gif.github.io/caladapt-docs/data-catalog.html#global-climate-models-gcm","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/gcms.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Global climate models — gcms","text":"following GCMs selected California state agencies priority models Fourth Assessment Research available thru Cal-Adapt API. first four identified priority GCMs representing (see 4 priority models) HadGEM2-ES: Met Office Hadley Centre Instituto Nacional de Pesquisas Espaciais CNRM-CM5: Centre National de Recherches Météorologiques/ Centre Européen de Recherche et Formation Avancée en Calcul Scientifique CanESM2: Canadian Centre Climate Modelling Analysis MIROC5: Atmosphere Ocean Research Institute (University Tokyo), National Institute Environmental Studies, Japan Agency Marine-Earth Science Technology ACCESS1-0: Commonwealth Scientific Industrial Research Organization (CSIRO) Bureau Meteorology (BOM) Australia CCSM4: University Miami - RSMAS CESM1-BGC: Community Earth System Model Contributors CMCC-CMS: Centro Euro-Mediterraneo per Cambiamenti Climatici GFDL-CM3: NOAA Geophysical Fluid Dynamics Laboratory HadGEM2-CC: Met Office Hadley Centre","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/periods.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal aggregation periods — periods","title":"Temporal aggregation periods — periods","text":"Temporal aggregation periods raster series","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/periods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal aggregation periods — periods","text":"","code":"data(periods)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/periods.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Temporal aggregation periods — periods","text":"character vector three names temporal aggregation periods","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/periods.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Temporal aggregation periods — periods","text":"https://berkeley-gif.github.io/caladapt-docs/data-catalog.html#period","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/periods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Temporal aggregation periods — periods","text":"following temporal aggregation periods raster series available thru Cal-Adapt API. day: Daily values month: Monthly summary statistic year: Annual summary statistic 30yavg: 30 year summary statistic","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/plot.ca_apireq.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a ca_apireq object — plot.ca_apireq","title":"Plot a ca_apireq object — plot.ca_apireq","text":"Plot ca_apireq object","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/plot.ca_apireq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a ca_apireq object — plot.ca_apireq","text":"","code":"# S3 method for class 'ca_apireq' plot(   x,   basemap = c(\"Esri.WorldStreetMap\", \"OpenStreetMap\")[2],   locagrid = FALSE,   static = FALSE,   ... )"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/plot.ca_apireq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a ca_apireq object — plot.ca_apireq","text":"x Cal-Adapt API request basemap name basemap tile layer (see tm_basemap) locagrid Overlay portion LOCA downscaled grid static Plot static map instead interactive leaflet map ... Unused","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/print.ca_apireq.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a ca_apireq object — print.ca_apireq","title":"Print a ca_apireq object — print.ca_apireq","text":"Print ca_apireq object","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/print.ca_apireq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a ca_apireq object — print.ca_apireq","text":"","code":"# S3 method for class 'ca_apireq' print(x, ...)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/print.ca_apireq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a ca_apireq object — print.ca_apireq","text":"x Cal-Adapt API request ... Unused","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/print.ca_db_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a ca_db_info object — print.ca_db_info","title":"Print a ca_db_info object — print.ca_db_info","text":"Print ca_db_info object","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/print.ca_db_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a ca_db_info object — print.ca_db_info","text":"","code":"# S3 method for class 'ca_db_info' print(x, ...)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/print.ca_db_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a ca_db_info object — print.ca_db_info","text":"x object class ca_db_info ... Unused","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/scenarios.html","id":null,"dir":"Reference","previous_headings":"","what":"Scenarios — scenarios","title":"Scenarios — scenarios","text":"Carbon emission scenarios available Cal-Adapt API","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/scenarios.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scenarios — scenarios","text":"","code":"data(scenarios)"},{"path":"https://ucanr-igis.github.io/caladaptr/reference/scenarios.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Scenarios — scenarios","text":"character vector three abbreviated names carbon emissions scenarios","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/scenarios.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Scenarios — scenarios","text":"https://berkeley-gif.github.io/caladapt-docs/data-catalog.html#scenarios","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/scenarios.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scenarios — scenarios","text":"following carbon emission scenarios available thru Cal-Adapt API. rcp45: RCP 4.5 (Emissions peak around 2040, decline) rcp85: RCP 8.5 (Emissions continue rise strongly 2050 plateau) historical: Historical","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/stopwarn.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function used by ca_apicalls() to handle issues discovered. — stopwarn","title":"Internal function used by ca_apicalls() to handle issues discovered. — stopwarn","text":"mostly keep code clean. pf=TRUE, just logged genl_msgs, gval_msgs, grst_msgs. stop_msg message show problem deal-breaker gval_msgs, grst_msgs messages show context getvals getrst (sometimes different) neither gval_msgs grst_msgs passed, error logged (pf=TRUE) code stopped (pf=FALSE) pf = FALSE stop_msg value, stop() called","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/reference/stopwarn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function used by ca_apicalls() to handle issues discovered. — stopwarn","text":"","code":"stopwarn(pf, check_for, stop_msg = NULL, gval_msg = NULL, grst_msg = NULL)"},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-070-2025-05-11","dir":"Changelog","previous_headings":"","what":"caladaptr 0.7.0 (2025-05-11)","title":"caladaptr 0.7.0 (2025-05-11)","text":"ca_aoipreset_geom: fixed error caused function called without loading package (.e., caladaptr::ca_aoipreset_geom). (#5) plot.ca_apireq: updated argument names tmap v3 v4. vignettes converted pre-computed Rmds, figures given alt text (’ll render R-Universe - hopefully!) add variable block_area_mi2 argument ca_biggeom_blocks (@dlebauer, #3)","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-069-2024-05-23","dir":"Changelog","previous_headings":"","what":"caladaptr 0.6.9 (2024-05-23)","title":"caladaptr 0.6.9 (2024-05-23)","text":"ca_loc_pt: fixed issue coords data frame columns names x y","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-068-2022-11-29","dir":"Changelog","previous_headings":"","what":"caladaptr 0.6.8 (2022-11-29)","title":"caladaptr 0.6.8 (2022-11-29)","text":"ca_getvals_db(), ca_getvals_tbl(): trapped error preset AOI falls outside LOCA grid (e.g., Farallon Islands HUC10 watershed)","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-067-2022-11-11","dir":"Changelog","previous_headings":"","what":"caladaptr 0.6.7 (2022-11-11)","title":"caladaptr 0.6.7 (2022-11-11)","text":"test-getvals-db(): updated test data catalog updated","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-066-2022-04-16","dir":"Changelog","previous_headings":"","what":"caladaptr 0.6.6 (2022-04-16)","title":"caladaptr 0.6.6 (2022-04-16)","text":"ca_preflight(): modified render messages differently non-interactive contexts (.e., Rmarkdown) format.ca_apireq(), print.ca_apireq(): modified output appears RMarkdown documents (color codes removed) bbox_resize(): utility function resize bounding box object (returned sf::st_bbox()) passing either scaling factor fixed offset; used internally exported convenience. data catalog updated","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-065-2022-02-10","dir":"Changelog","previous_headings":"","what":"caladaptr 0.6.5 (2022-02-10)","title":"caladaptr 0.6.5 (2022-02-10)","text":"ca_example_apireq: additional example added","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-064-2022-01-02","dir":"Changelog","previous_headings":"","what":"caladaptr 0.6.4 (2022-01-02)","title":"caladaptr 0.6.4 (2022-01-02)","text":"ca_getvals_tbl(), ca_getrst_stars(), ca_getvals_db(): added .call = F several calls stop() ca_loc_pt(): added error checks NAs duplicate coordinates coords ca_loc_aoipreset(): added error check NAs duplicate values idval ca_slug(): added error check NAs duplicate values slug ca_apicalls(): Added duplicate location check loc_check = TRUE; stopwarn() split separate function cvars: updated “ET” “et” reflect change made API updated raster series data catalog (inst/extdata/ca_catalog_rs.csv) ca_getvals_tbl(): added timeout argument","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-063-2021-12-07","dir":"Changelog","previous_headings":"","what":"caladaptr 0.6.3 (2021-12-07)","title":"caladaptr 0.6.3 (2021-12-07)","text":"ca_getvals_tbl(): added timeout argument ability increase amount time httr returns timeout error","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-062-2021-09-06","dir":"Changelog","previous_headings":"","what":"caladaptr 0.6.2 (2021-09-06)","title":"caladaptr 0.6.2 (2021-09-06)","text":"Added copyright holder funding organization package authors Updated package license GPL-3 GPL (>= 3) logo updated - text border now green instead red","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-061-2021-09-06","dir":"Changelog","previous_headings":"","what":"caladaptr 0.6.1 (2021-09-06)","title":"caladaptr 0.6.1 (2021-09-06)","text":"Version 0.6.1 fairly significant update, several new improved functions especially downloading working rasters, SQLite databases, improved preflight testing API requests, data catalog searching, customizing messages package-wide color scheme, making function names consistent. Also 5 vignettes API Requests, Large Queries, Rasters Part , II, III. caladaptr now depends R version 3.6. ca_getrst_stars(): modified save additional attribute data sidecar files (e.g., gcm, scenario, climate variable, etc.); progress bar disabled quiet = TRUE (e.g., rmd); normalize_path argument added; overwrite argument added; sidecar_write argument renamed sidecar ca_read_stars(): deprecated (renamed ca_stars_read()) ca_stars_read(): replacement ca_read_stars(), updated accept vector TIF files names (instead one), return list stars objects; read_sidecar argument renamed sidecar; added proxy argument imports TIFs stars proxy objects (.e., disk pointers) ca_stars_index: new function create index list stars rasters downloaded ca_getrst_stars bundled list ca_read_stars ca_stars_6d(): combines stars rasters different climate variables, GCMs, emissions scenarios single 6-dimensional raster (x, y, date three dimensions) ca_biggeom_blocks(): new function takes large geom returns simple feature data frame rectangular blocks one small enough download TIFFs Cal-Adapt API ca_stars_mosaic(): new function mosaic stars rasters ca_preflight(): removed unused quiet argument; errors ca_apicalls() now grouped formatted ca_settings(): new function customize package settings including text output colors ca_apicalls(): ignore_spag renamed spag_check; new argument check_for; preflight renamed pf ca_getvals_tbl(): modified ca_apicalls() called, omit_col argument added ca_getvals_db(): updated support Cal-Adapt API requests Livneh data; omit_col argument added ca_catalog_search(): new function search raster series slug view properties ca_catalog_rs(): raster series data catalog updated (n=949) ca_read_db(): deprecated renamed ca_db_read() consistent API ca_db_read(): added lkp_sql vals_tbl attributes result ca_db_info() format.ca_db_info(): enhanced read SQL statements sidecar files, save print multiple SQL statements ca_catalog_fetch(): now exported unit tests: new tests created downloading rasters saving data SQLite; 68 five new vignettes: API Requests, Large Queries, Rasters Part , II, III","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-050-2021-05-17","dir":"Changelog","previous_headings":"","what":"caladaptr 0.5.0 (2021-05-17)","title":"caladaptr 0.5.0 (2021-05-17)","text":"ca_catalog_fetch(): trapped error tres property missing ca_apireq(): added element livneh ca_livneh(): new function specify Livneh dataset cvars: expanded include VIC variables ca_apicalls(): added additional error checks; support livneh dataset ca_preflight(): new function check API request errors","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-046-2021-01-12","dir":"Changelog","previous_headings":"","what":"caladaptr 0.4.6 (2021-01-12)","title":"caladaptr 0.4.6 (2021-01-12)","text":"ca_db_info(): returned result longer invisible ca_getvals_tbl(): shiny_progress argument added show progress bar Shiny apps ca_getvals_db(): added write_sidecar argument - writes sidecar file next SQLite file ca_read_db(): imports SQLite file created ca_getvals_db(), returning remote tibble shiny added imports","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-045-2021-01-02","dir":"Changelog","previous_headings":"","what":"caladaptr 0.4.5 (2021-01-02)","title":"caladaptr 0.4.5 (2021-01-02)","text":"highlight update improvements ca_getrst_stars(). can now download cropped rasters user-defined sf data frames well, points, preset areas interest. Rasters can also masked polygon boundary. ca_getrst_stars(): added support sf data frames point locations; added mask merge_geom arguments geojsonsf zip added imports ca_apicalls(): fixed bug api_url ignore_spag = TRUE","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-044-2020-12-07","dir":"Changelog","previous_headings":"","what":"caladaptr 0.4.4 (2020-12-07)","title":"caladaptr 0.4.4 (2020-12-07)","text":"ca_example_apireq(): updated example #1 ca_locagrid_geom(): zip file download source changed github.com/ucanr-igis/caladaptr-res/… ca_aoipreset_geom(): zip file download source changed github.com/ucanr-igis/caladaptr-res/… ca_getrst_stars(): added ca_read_stars(): added","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-043-2020-12-06","dir":"Changelog","previous_headings":"","what":"caladaptr 0.4.3 (2020-12-06)","title":"caladaptr 0.4.3 (2020-12-06)","text":"ca_getvals_tbl(), ca_getvals_db() ca_apicalls(): removed format=json parameter favor accept_json() ca_resp_check(): deleted (functionality absorbed ca_getvals_tbl() & ca_getvals_db()) testhttp added suggests; tests added ca_lof_sf(): trap added multipoint features (Cal-Adapt server treats individual points, hence used) ca_apicalls(): removed gson_fn_base list object returned ca_example_apireq(): added ca_locagrid_geom(): added ca_aoipreset_geom(): temporary zip file(s) now deleted longer needed; source directory zipfiles GitHub changed ‘aoipreset_geoms’ just ‘geoms’; check internet connection added plot.ca_apireq(): locagrid argument added overlay loca grid","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-042-2020-11-18","dir":"Changelog","previous_headings":"","what":"caladaptr 0.4.2 (2020-11-18)","title":"caladaptr 0.4.2 (2020-11-18)","text":"plot.ca_apireq(): default symbol size tweaked point features","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-041-2020-11-10","dir":"Changelog","previous_headings":"","what":"caladaptr 0.4.1 (2020-11-10)","title":"caladaptr 0.4.1 (2020-11-10)","text":"ca_getvals() split ca_getvals_tbl() ca_getvals_db(); user_agent added headers; support sf objects added ca_lof_sf(): overhauled ca_apicalls(): new method hashing API calls implemented; now returns list object aoipreset_idvals: name removed field uniquely identifying counties ca_loc_sf() overhauled package digest added imports","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-040-2020-10-11","dir":"Changelog","previous_headings":"","what":"caladaptr 0.4.0 (2020-10-11)","title":"caladaptr 0.4.0 (2020-10-11)","text":"ca_slug() added ca_getvals() completely overhauled - returns tibble ca_apicalls() added ca_vals2tbl() deleted (longer needed) aoipreset_idflds: name removed field uniquely identifying counties plot.ca_apireq(): added static argument packages curl, RSQLite, dbplyr, fastmatch added imports (.e., required)","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-030-2020-09-18","dir":"Changelog","previous_headings":"","what":"caladaptr 0.3.0 (2020-09-18)","title":"caladaptr 0.3.0 (2020-09-18)","text":"updated read.csv calls ca_catalog_rs() consistent behavior R3.x R4.x. updated ca_getvals() ) handle aoipreset locations idval = NULL, ii) display progress bar location queried","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-029-2020-08-31","dir":"Changelog","previous_headings":"","what":"caladaptr 0.2.9 (2020-08-31)","title":"caladaptr 0.2.9 (2020-08-31)","text":"Fixed capitalization bug ca_loc_pt() Expanding function help numerous functions","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-028-2020-08-29","dir":"Changelog","previous_headings":"","what":"caladaptr 0.2.8 (2020-08-29)","title":"caladaptr 0.2.8 (2020-08-29)","text":"Added argument force_day_one ca_vals2tbl() Added NEWS.md file track changes package.","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-027-2020-08-28","dir":"Changelog","previous_headings":"","what":"caladaptr 0.2.7 (2020-08-28)","title":"caladaptr 0.2.7 (2020-08-28)","text":"Numerous little updates Added R notebook caladaptr_intro.Rmd","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-026-2020-08-27","dir":"Changelog","previous_headings":"","what":"caladaptr 0.2.6 (2020-08-27)","title":"caladaptr 0.2.6 (2020-08-27)","text":"Numerous updates","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-025-2020-08-21","dir":"Changelog","previous_headings":"","what":"caladaptr 0.2.5 (2020-08-21)","title":"caladaptr 0.2.5 (2020-08-21)","text":"Numerous updates","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-024-2020-08-12","dir":"Changelog","previous_headings":"","what":"caladaptr 0.2.4 (2020-08-12)","title":"caladaptr 0.2.4 (2020-08-12)","text":"Numerous updates","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-023-2020-08-11","dir":"Changelog","previous_headings":"","what":"caladaptr 0.2.3 (2020-08-11)","title":"caladaptr 0.2.3 (2020-08-11)","text":"Numerous updates","code":""},{"path":"https://ucanr-igis.github.io/caladaptr/news/index.html","id":"caladaptr-022-2020-08-09","dir":"Changelog","previous_headings":"","what":"caladaptr 0.2.2 (2020-08-09)","title":"caladaptr 0.2.2 (2020-08-09)","text":"Initial release","code":""}]
